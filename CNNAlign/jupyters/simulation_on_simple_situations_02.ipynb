{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, sys\n",
    "root_path = os.path.abspath('.').split('jupyters')[0]\n",
    "sys.path.append(root_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import argparse\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "from functools import partial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "map_size = (10, 10)\n",
    "#py_func = partial(data_process, map_size = map_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "correlations = np.zeros(map_size, np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]], dtype=float32)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "correlations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_corr_map(mp, map_size):\n",
    "    #mp = mp.numpy()\n",
    "    correlations = np.zeros(map_size, np.float32)\n",
    "    for i in range(map_size[0]):\n",
    "        for j in range(map_size[1]):\n",
    "            if i+mp == j:\n",
    "                correlations[i,j] += 1\n",
    "    return correlations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 1. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 1. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 1. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 1. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 1. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 1. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 1. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 1. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 1.]]\n"
     ]
    }
   ],
   "source": [
    "correlations = make_corr_map(0, map_size)\n",
    "print(correlations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0. 1. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 1. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 1. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 1. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 1. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 1. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 1. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 1. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 1.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n"
     ]
    }
   ],
   "source": [
    "correlations = make_corr_map(1, map_size)\n",
    "print(correlations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0. 0. 1. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 1. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 1. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 1. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 1. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 1. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 1. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 1.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n"
     ]
    }
   ],
   "source": [
    "correlations = make_corr_map(2, map_size)\n",
    "print(correlations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 1. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 1. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 1. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 1. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 1. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 1. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 1. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 1. 0.]]\n"
     ]
    }
   ],
   "source": [
    "correlations = make_corr_map(-1, map_size)\n",
    "print(correlations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 1. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 1. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 1. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 1. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 1. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 1. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 1. 0. 0.]]\n"
     ]
    }
   ],
   "source": [
    "correlations = make_corr_map(-2, map_size)\n",
    "print(correlations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gen_integer():\n",
    "    while True:\n",
    "        yield tf.random.uniform(shape=[1], minval = -10, maxval=11, dtype=tf.int32, seed=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_process(mp, map_size):\n",
    "    mp = mp.numpy()\n",
    "    correlations = np.zeros(map_size, np.float32)\n",
    "    for i in range(map_size[0]):\n",
    "        for j in range(map_size[1]):\n",
    "            if i+mp == j:\n",
    "                correlations[i,j] += 1\n",
    "    return mp, correlations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "py_func = partial(data_process, map_size = map_size)\n",
    "def map_function(motion_paramters):\n",
    "    return tf.py_function(py_func, [motion_paramters], [tf.float32, tf.float32])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds = tf.data.Dataset.from_generator(gen_integer, output_types=tf.int32)\n",
    "ds = ds.map(map_function)\n",
    "ds = ds.batch(100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(\n",
      "[[  2.]\n",
      " [-10.]\n",
      " [ -6.]\n",
      " [ -3.]\n",
      " [  7.]\n",
      " [  6.]\n",
      " [ -5.]\n",
      " [ -5.]\n",
      " [  3.]\n",
      " [ -1.]\n",
      " [ -2.]\n",
      " [  6.]\n",
      " [ -7.]\n",
      " [ 10.]\n",
      " [  0.]\n",
      " [ -4.]\n",
      " [  7.]\n",
      " [ -1.]\n",
      " [  2.]\n",
      " [  0.]\n",
      " [  9.]\n",
      " [ -4.]\n",
      " [  9.]\n",
      " [  1.]\n",
      " [ -6.]\n",
      " [ 10.]\n",
      " [  7.]\n",
      " [  7.]\n",
      " [ 10.]\n",
      " [ -6.]\n",
      " [  8.]\n",
      " [ -2.]\n",
      " [ -2.]\n",
      " [  0.]\n",
      " [  1.]\n",
      " [ -6.]\n",
      " [-10.]\n",
      " [  9.]\n",
      " [ -5.]\n",
      " [ -8.]\n",
      " [-10.]\n",
      " [  7.]\n",
      " [ -6.]\n",
      " [  5.]\n",
      " [  4.]\n",
      " [ -3.]\n",
      " [  7.]\n",
      " [ 10.]\n",
      " [ -8.]\n",
      " [  3.]\n",
      " [  2.]\n",
      " [ -3.]\n",
      " [ -1.]\n",
      " [ -8.]\n",
      " [ -8.]\n",
      " [ 10.]\n",
      " [ -6.]\n",
      " [  2.]\n",
      " [  2.]\n",
      " [ -3.]\n",
      " [  6.]\n",
      " [ -9.]\n",
      " [ 10.]\n",
      " [  9.]\n",
      " [  9.]\n",
      " [ -1.]\n",
      " [  0.]\n",
      " [  0.]\n",
      " [  8.]\n",
      " [ -4.]\n",
      " [ -7.]\n",
      " [ -2.]\n",
      " [ -8.]\n",
      " [  4.]\n",
      " [ -8.]\n",
      " [  9.]\n",
      " [  0.]\n",
      " [ -7.]\n",
      " [ -5.]\n",
      " [  1.]\n",
      " [  5.]\n",
      " [  0.]\n",
      " [  5.]\n",
      " [  4.]\n",
      " [ -5.]\n",
      " [ -6.]\n",
      " [ -5.]\n",
      " [  0.]\n",
      " [ -7.]\n",
      " [  7.]\n",
      " [ -5.]\n",
      " [  9.]\n",
      " [ -1.]\n",
      " [ -9.]\n",
      " [  6.]\n",
      " [  2.]\n",
      " [ -6.]\n",
      " [ -4.]\n",
      " [  9.]\n",
      " [ 10.]], shape=(100, 1), dtype=float32)\n",
      "tf.Tensor([-10.], shape=(1,), dtype=float32) tf.Tensor([10.], shape=(1,), dtype=float32)\n",
      "tf.Tensor(\n",
      "[[[0. 0. 1. ... 0. 0. 0.]\n",
      "  [0. 0. 0. ... 0. 0. 0.]\n",
      "  [0. 0. 0. ... 0. 0. 0.]\n",
      "  ...\n",
      "  [0. 0. 0. ... 0. 0. 1.]\n",
      "  [0. 0. 0. ... 0. 0. 0.]\n",
      "  [0. 0. 0. ... 0. 0. 0.]]\n",
      "\n",
      " [[0. 0. 0. ... 0. 0. 0.]\n",
      "  [0. 0. 0. ... 0. 0. 0.]\n",
      "  [0. 0. 0. ... 0. 0. 0.]\n",
      "  ...\n",
      "  [0. 0. 0. ... 0. 0. 0.]\n",
      "  [0. 0. 0. ... 0. 0. 0.]\n",
      "  [0. 0. 0. ... 0. 0. 0.]]\n",
      "\n",
      " [[0. 0. 0. ... 0. 0. 0.]\n",
      "  [0. 0. 0. ... 0. 0. 0.]\n",
      "  [0. 0. 0. ... 0. 0. 0.]\n",
      "  ...\n",
      "  [0. 1. 0. ... 0. 0. 0.]\n",
      "  [0. 0. 1. ... 0. 0. 0.]\n",
      "  [0. 0. 0. ... 0. 0. 0.]]\n",
      "\n",
      " ...\n",
      "\n",
      " [[0. 0. 0. ... 0. 0. 0.]\n",
      "  [0. 0. 0. ... 0. 0. 0.]\n",
      "  [0. 0. 0. ... 0. 0. 0.]\n",
      "  ...\n",
      "  [0. 0. 0. ... 0. 0. 0.]\n",
      "  [0. 0. 0. ... 0. 0. 0.]\n",
      "  [0. 0. 0. ... 0. 0. 0.]]\n",
      "\n",
      " [[0. 0. 0. ... 0. 0. 1.]\n",
      "  [0. 0. 0. ... 0. 0. 0.]\n",
      "  [0. 0. 0. ... 0. 0. 0.]\n",
      "  ...\n",
      "  [0. 0. 0. ... 0. 0. 0.]\n",
      "  [0. 0. 0. ... 0. 0. 0.]\n",
      "  [0. 0. 0. ... 0. 0. 0.]]\n",
      "\n",
      " [[0. 0. 0. ... 0. 0. 0.]\n",
      "  [0. 0. 0. ... 0. 0. 0.]\n",
      "  [0. 0. 0. ... 0. 0. 0.]\n",
      "  ...\n",
      "  [0. 0. 0. ... 0. 0. 0.]\n",
      "  [0. 0. 0. ... 0. 0. 0.]\n",
      "  [0. 0. 0. ... 0. 0. 0.]]], shape=(100, 10, 10), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "for mp, corr in ds.take(1):\n",
    "    print(mp)\n",
    "    print(min(mp), max(mp))\n",
    "    print(corr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "layers = tf.keras.layers\n",
    "#dir(layers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loss_fn(pred, label):\n",
    "    loss = tf.sqrt(tf.pow(pred - label, 2))\n",
    "    loss_mean = tf.reduce_mean(loss)\n",
    "    return loss_mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Layer conv1d is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d (Conv1D)              multiple                  93        \n",
      "_________________________________________________________________\n",
      "conv1d_1 (Conv1D)            multiple                  30        \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            multiple                  0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                multiple                  19        \n",
      "=================================================================\n",
      "Total params: 142\n",
      "Trainable params: 142\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "10 iter loss :  5.6745405\n",
      "20 iter loss :  4.6946363\n",
      "30 iter loss :  4.963554\n",
      "40 iter loss :  4.890676\n",
      "50 iter loss :  4.3484406\n",
      "60 iter loss :  4.373718\n",
      "70 iter loss :  3.85291\n",
      "80 iter loss :  4.273892\n",
      "90 iter loss :  3.5273328\n",
      "100 iter loss :  2.7849991\n",
      "110 iter loss :  3.8273058\n",
      "120 iter loss :  3.8628597\n",
      "130 iter loss :  2.9293232\n",
      "140 iter loss :  2.8420591\n",
      "150 iter loss :  2.970322\n",
      "160 iter loss :  2.813371\n",
      "170 iter loss :  1.6468602\n",
      "180 iter loss :  3.747525\n",
      "190 iter loss :  2.090798\n",
      "200 iter loss :  2.063028\n",
      "210 iter loss :  2.351018\n",
      "220 iter loss :  3.1256166\n",
      "230 iter loss :  2.561669\n",
      "240 iter loss :  2.276454\n",
      "250 iter loss :  1.7719779\n",
      "260 iter loss :  3.067497\n",
      "270 iter loss :  2.3159254\n",
      "280 iter loss :  2.8614156\n",
      "290 iter loss :  2.3703542\n",
      "300 iter loss :  1.6972584\n",
      "310 iter loss :  2.2609735\n",
      "320 iter loss :  1.9154271\n",
      "330 iter loss :  2.1579554\n",
      "340 iter loss :  1.5670377\n",
      "350 iter loss :  1.535007\n",
      "360 iter loss :  2.3173459\n",
      "370 iter loss :  2.25002\n",
      "380 iter loss :  2.1812525\n",
      "390 iter loss :  2.1300068\n",
      "400 iter loss :  1.6035223\n",
      "410 iter loss :  1.1361405\n",
      "420 iter loss :  1.696811\n",
      "430 iter loss :  1.523417\n",
      "440 iter loss :  2.0136285\n",
      "450 iter loss :  1.6888013\n",
      "460 iter loss :  1.4170969\n",
      "470 iter loss :  1.5808014\n",
      "480 iter loss :  1.5702344\n",
      "490 iter loss :  1.208233\n",
      "500 iter loss :  1.1407824\n",
      "510 iter loss :  1.6811421\n",
      "520 iter loss :  1.5207617\n",
      "530 iter loss :  1.5921437\n",
      "540 iter loss :  1.5140129\n",
      "550 iter loss :  1.5765014\n",
      "560 iter loss :  1.3753301\n",
      "570 iter loss :  1.8003316\n",
      "580 iter loss :  0.9966071\n",
      "590 iter loss :  1.8710487\n",
      "600 iter loss :  1.9189839\n",
      "610 iter loss :  2.0293732\n",
      "620 iter loss :  1.4952631\n",
      "630 iter loss :  1.2834195\n",
      "640 iter loss :  1.5671479\n",
      "650 iter loss :  2.6082644\n",
      "660 iter loss :  1.7223947\n",
      "670 iter loss :  1.437772\n",
      "680 iter loss :  1.3476815\n",
      "690 iter loss :  0.9718612\n",
      "700 iter loss :  1.1542627\n",
      "710 iter loss :  0.9268635\n",
      "720 iter loss :  1.738267\n",
      "730 iter loss :  1.190327\n",
      "740 iter loss :  1.8679487\n",
      "750 iter loss :  1.5685952\n",
      "760 iter loss :  1.1766183\n",
      "770 iter loss :  1.629377\n",
      "780 iter loss :  1.4584798\n",
      "790 iter loss :  1.522963\n",
      "800 iter loss :  1.2636473\n",
      "810 iter loss :  1.387491\n",
      "820 iter loss :  1.8397223\n",
      "830 iter loss :  1.6844052\n",
      "840 iter loss :  1.5363839\n",
      "850 iter loss :  1.7129349\n",
      "860 iter loss :  1.3742752\n",
      "870 iter loss :  1.5336313\n",
      "880 iter loss :  1.493229\n",
      "890 iter loss :  0.9877162\n",
      "900 iter loss :  2.1308718\n",
      "910 iter loss :  2.3046007\n",
      "920 iter loss :  1.9431429\n",
      "930 iter loss :  1.1895666\n",
      "940 iter loss :  0.9859613\n",
      "950 iter loss :  1.1474056\n",
      "960 iter loss :  0.66913575\n",
      "970 iter loss :  1.2607968\n",
      "980 iter loss :  1.1125946\n",
      "990 iter loss :  1.4637539\n",
      "1000 iter loss :  1.3635372\n",
      "1010 iter loss :  1.5637102\n",
      "1020 iter loss :  1.5290393\n",
      "1030 iter loss :  1.5761348\n",
      "1040 iter loss :  1.3946887\n",
      "1050 iter loss :  0.83308434\n",
      "1060 iter loss :  1.4009248\n",
      "1070 iter loss :  1.2407252\n",
      "1080 iter loss :  0.9063178\n",
      "1090 iter loss :  1.7437615\n",
      "1100 iter loss :  0.8972752\n",
      "1110 iter loss :  1.7126878\n",
      "1120 iter loss :  0.84361476\n",
      "1130 iter loss :  1.3498845\n",
      "1140 iter loss :  1.5213802\n",
      "1150 iter loss :  1.119565\n",
      "1160 iter loss :  1.0798292\n",
      "1170 iter loss :  1.8584322\n",
      "1180 iter loss :  1.2418327\n",
      "1190 iter loss :  1.263919\n",
      "1200 iter loss :  1.0846747\n",
      "1210 iter loss :  1.0686897\n",
      "1220 iter loss :  1.1609825\n",
      "1230 iter loss :  1.0343271\n",
      "1240 iter loss :  1.2213104\n",
      "1250 iter loss :  1.702301\n",
      "1260 iter loss :  1.6886342\n",
      "1270 iter loss :  2.1888566\n",
      "1280 iter loss :  1.3229976\n",
      "1290 iter loss :  1.0804231\n",
      "1300 iter loss :  1.4677277\n",
      "1310 iter loss :  0.9628691\n",
      "1320 iter loss :  1.1423622\n",
      "1330 iter loss :  1.2292094\n",
      "1340 iter loss :  1.33941\n",
      "1350 iter loss :  0.8720195\n",
      "1360 iter loss :  1.5559169\n",
      "1370 iter loss :  1.2769539\n",
      "1380 iter loss :  1.9683816\n",
      "1390 iter loss :  0.885457\n",
      "1400 iter loss :  1.4277705\n",
      "1410 iter loss :  1.1723765\n",
      "1420 iter loss :  1.214397\n",
      "1430 iter loss :  1.313938\n",
      "1440 iter loss :  1.0306108\n",
      "1450 iter loss :  1.6490679\n",
      "1460 iter loss :  1.9214445\n",
      "1470 iter loss :  2.3313794\n",
      "1480 iter loss :  1.0397391\n",
      "1490 iter loss :  1.6642512\n",
      "1500 iter loss :  1.1965446\n",
      "1510 iter loss :  1.1193062\n",
      "1520 iter loss :  0.7185903\n",
      "1530 iter loss :  1.7652175\n",
      "1540 iter loss :  1.7366948\n",
      "1550 iter loss :  0.6513452\n",
      "1560 iter loss :  1.0042301\n",
      "1570 iter loss :  1.1254846\n",
      "1580 iter loss :  1.3174713\n",
      "1590 iter loss :  1.0329813\n",
      "1600 iter loss :  1.6099056\n",
      "1610 iter loss :  1.4434438\n",
      "1620 iter loss :  1.5189087\n",
      "1630 iter loss :  0.6463224\n",
      "1640 iter loss :  1.3230706\n",
      "1650 iter loss :  1.1446104\n",
      "1660 iter loss :  1.0245461\n",
      "1670 iter loss :  1.2706933\n",
      "1680 iter loss :  1.4861282\n",
      "1690 iter loss :  0.9264035\n",
      "1700 iter loss :  1.1215091\n",
      "1710 iter loss :  1.0784978\n",
      "1720 iter loss :  0.8843523\n",
      "1730 iter loss :  1.3469739\n",
      "1740 iter loss :  2.3141916\n",
      "1750 iter loss :  1.8920649\n",
      "1760 iter loss :  1.0416362\n",
      "1770 iter loss :  1.0210189\n",
      "1780 iter loss :  1.1245835\n",
      "1790 iter loss :  0.7764799\n",
      "1800 iter loss :  1.3539138\n",
      "1810 iter loss :  1.5387039\n",
      "1820 iter loss :  1.2635757\n",
      "1830 iter loss :  1.4917206\n",
      "1840 iter loss :  1.0905101\n",
      "1850 iter loss :  1.4353176\n",
      "1860 iter loss :  1.3944371\n",
      "1870 iter loss :  1.6345642\n",
      "1880 iter loss :  1.1792663\n",
      "1890 iter loss :  1.0527654\n",
      "1900 iter loss :  1.2098336\n",
      "1910 iter loss :  1.6059517\n",
      "1920 iter loss :  1.0902219\n",
      "1930 iter loss :  1.6446846\n",
      "1940 iter loss :  1.2828543\n",
      "1950 iter loss :  1.7812959\n",
      "1960 iter loss :  1.0548794\n",
      "1970 iter loss :  1.0883967\n",
      "1980 iter loss :  0.8400846\n",
      "1990 iter loss :  0.8164498\n",
      "2000 iter loss :  0.9461286\n",
      "2010 iter loss :  1.2196269\n",
      "2020 iter loss :  1.0562966\n",
      "2030 iter loss :  1.3795737\n",
      "2040 iter loss :  1.3167728\n",
      "2050 iter loss :  0.8924212\n",
      "2060 iter loss :  1.4064769\n",
      "2070 iter loss :  0.8301896\n",
      "2080 iter loss :  0.98825943\n",
      "2090 iter loss :  0.95767695\n",
      "2100 iter loss :  1.1625518\n",
      "2110 iter loss :  1.100292\n",
      "2120 iter loss :  1.0446811\n",
      "2130 iter loss :  1.2489086\n",
      "2140 iter loss :  1.3817573\n",
      "2150 iter loss :  1.1646452\n",
      "2160 iter loss :  1.0136834\n",
      "2170 iter loss :  1.5769784\n",
      "2180 iter loss :  1.2121558\n",
      "2190 iter loss :  1.0999722\n",
      "2200 iter loss :  0.95520484\n",
      "2210 iter loss :  1.0905488\n",
      "2220 iter loss :  1.5536239\n",
      "2230 iter loss :  1.1414807\n",
      "2240 iter loss :  1.3352057\n",
      "2250 iter loss :  0.91672456\n",
      "2260 iter loss :  0.7504029\n",
      "2270 iter loss :  1.2803172\n",
      "2280 iter loss :  1.0966501\n",
      "2290 iter loss :  1.0483073\n",
      "2300 iter loss :  1.5483527\n",
      "2310 iter loss :  1.0590546\n",
      "2320 iter loss :  1.2553403\n",
      "2330 iter loss :  1.015665\n",
      "2340 iter loss :  1.0595009\n",
      "2350 iter loss :  1.160231\n",
      "2360 iter loss :  1.2494683\n",
      "2370 iter loss :  1.1080276\n",
      "2380 iter loss :  1.467876\n",
      "2390 iter loss :  1.1515273\n",
      "2400 iter loss :  1.3779762\n",
      "2410 iter loss :  0.9735342\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2420 iter loss :  1.1817261\n",
      "2430 iter loss :  1.6653708\n",
      "2440 iter loss :  0.9867492\n",
      "2450 iter loss :  1.1893284\n",
      "2460 iter loss :  1.0412598\n",
      "2470 iter loss :  1.0500995\n",
      "2480 iter loss :  0.6134098\n",
      "2490 iter loss :  1.2944516\n",
      "2500 iter loss :  1.0083756\n",
      "2510 iter loss :  1.1965901\n",
      "2520 iter loss :  1.1261816\n",
      "2530 iter loss :  1.4677978\n",
      "2540 iter loss :  1.5881397\n",
      "2550 iter loss :  1.2386605\n",
      "2560 iter loss :  1.3636844\n",
      "2570 iter loss :  0.85446286\n",
      "2580 iter loss :  1.0803494\n",
      "2590 iter loss :  1.2980953\n",
      "2600 iter loss :  1.8345194\n",
      "2610 iter loss :  1.0737702\n",
      "2620 iter loss :  1.3893772\n",
      "2630 iter loss :  1.4651\n",
      "2640 iter loss :  1.2454342\n",
      "2650 iter loss :  1.2154254\n",
      "2660 iter loss :  1.4736372\n",
      "2670 iter loss :  1.6611444\n",
      "2680 iter loss :  1.7089283\n",
      "2690 iter loss :  1.1692591\n",
      "2700 iter loss :  0.9537831\n",
      "2710 iter loss :  0.9321528\n",
      "2720 iter loss :  1.0528625\n",
      "2730 iter loss :  0.7808732\n"
     ]
    }
   ],
   "source": [
    "regressor = tf.keras.Sequential([layers.Conv1D(3, 3),\n",
    "                             layers.Conv1D(3, 3),\n",
    "                             layers.Flatten(),\n",
    "                             layers.Dense(1)])\n",
    "pred = regressor(np.ones([16,map_size[0],map_size[1]]))\n",
    "pred = tf.reshape(pred, [-1, 1])\n",
    "regressor.summary()\n",
    "\n",
    "i = 0\n",
    "x = []\n",
    "x_loss1 = []\n",
    "optimizer = tf.keras.optimizers.SGD(learning_rate=0.05)\n",
    "for epoch in range(4000):\n",
    "    i+= 1\n",
    "    x.append(i)\n",
    "    for mp, correlations in ds.take(1):\n",
    "        with tf.GradientTape() as tape:\n",
    "            pred = regressor(correlations)\n",
    "            pred = tf.reshape(pred, [-1, 1])\n",
    "            loss = loss_fn(pred, mp)\n",
    "            x_loss1.append(loss)\n",
    "        gradients = tape.gradient(loss, regressor.trainable_variables)\n",
    "        optimizer.apply_gradients(zip(gradients, regressor.trainable_variables)) \n",
    "        if i % 10 == 0:\n",
    "            print(i, \"iter loss : \", loss.numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "regressor = tf.keras.Sequential([layers.Conv1D(5, 3),\n",
    "                             layers.Conv1D(3, 3),\n",
    "                             layers.Flatten(),\n",
    "                             layers.Dense(1)])\n",
    "pred = regressor(np.ones([16,10,10]))\n",
    "pred = tf.reshape(pred, [-1, 1])\n",
    "regressor.summary()\n",
    "\n",
    "i = 0\n",
    "x = []\n",
    "x_loss2 = []\n",
    "optimizer = tf.keras.optimizers.SGD(learning_rate=0.01)\n",
    "for epoch in range(4000):\n",
    "    i+= 1\n",
    "    x.append(i)\n",
    "    for mp, correlations in ds.take(1):\n",
    "        with tf.GradientTape() as tape:\n",
    "            pred = regressor(correlations)\n",
    "            pred = tf.reshape(pred, [-1, 1])\n",
    "            loss = loss_fn(pred, mp)\n",
    "            x_loss2.append(loss)\n",
    "        gradients = tape.gradient(loss, regressor.trainable_variables)\n",
    "        optimizer.apply_gradients(zip(gradients, regressor.trainable_variables)) \n",
    "        if i % 10 == 0:\n",
    "            print(i, \"iter loss : \", loss.numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "regressor = tf.keras.Sequential([layers.Conv1D(3, 3),\n",
    "                             layers.Conv1D(5, 3),\n",
    "                             layers.Flatten(),\n",
    "                             layers.Dense(1)])\n",
    "pred = regressor(np.ones([16,10,10]))\n",
    "pred = tf.reshape(pred, [-1, 1])\n",
    "regressor.summary()\n",
    "\n",
    "i = 0\n",
    "x = []\n",
    "x_loss3 = []\n",
    "optimizer = tf.keras.optimizers.SGD(learning_rate=0.01)\n",
    "for epoch in range(4000):\n",
    "    i+= 1\n",
    "    x.append(i)\n",
    "    for mp, correlations in ds.take(1):\n",
    "        with tf.GradientTape() as tape:\n",
    "            pred = regressor(correlations)\n",
    "            pred = tf.reshape(pred, [-1, 1])\n",
    "            loss = loss_fn(pred, mp)\n",
    "            x_loss3.append(loss)\n",
    "        gradients = tape.gradient(loss, regressor.trainable_variables)\n",
    "        optimizer.apply_gradients(zip(gradients, regressor.trainable_variables)) \n",
    "        if i % 10 == 0:\n",
    "            print(i, \"iter loss : \", loss.numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "fig = plt.figure()\n",
    "ax1 = fig.add_subplot(111)\n",
    "#ax2 = fig.add_subplot(122)\n",
    "ax1.title.set_text(\"training loss\")\n",
    "ax1.set_xlabel(\"epoch\")\n",
    "ax1.set_ylabel(\"training loss\")\n",
    "ax1.plot(np.array(x), np.array(x_loss1), label=\"3,3\")\n",
    "ax1.plot(np.array(x), np.array(x_loss2), label=\"5,3\")\n",
    "ax1.plot(np.array(x), np.array(x_loss3), label=\"3,5\")\n",
    "plt.legend(loc=2)\n",
    "\n",
    "# ax2.title.set_text(\"std-dev of correlations\")\n",
    "# ax2.set_xlabel(\"epoch\")\n",
    "# ax2.set_ylabel(\"std-dev\")\n",
    "# ax2.plot(np.array(x), np.array(y_score_std))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "correlations = make_corr_map(3, map_size)\n",
    "correlations = correlations[np.newaxis, :]\n",
    "print(correlations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for mp in range(-3, 4):\n",
    "    print(\"mp : {}\".format(mp))\n",
    "    correlations = make_corr_map(mp, map_size)\n",
    "    print(\"correlation map : {}\".format(correlations))\n",
    "    correlations = correlations[np.newaxis, :]\n",
    "    print(\"pred : {}\".format(regressor(correlations)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "correlations = make_corr_map(0, map_size)\n",
    "correlations = correlations[np.newaxis, :]\n",
    "print(correlations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x0 = regressor.layers[0](correlations)\n",
    "print(x0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x1 = regressor.layers[1](x0)\n",
    "print(x1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x2 = regressor.layers[2](x1)\n",
    "print(x2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(regressor.layers[0].get_weights())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(regressor.layers[1].get_weights())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(regressor.layers[3].get_weights())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

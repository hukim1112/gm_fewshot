{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, sys\n",
    "root_path = os.path.abspath('.').split('jupyters')[0]\n",
    "sys.path.append(root_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import argparse\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "from data_loader import load_data\n",
    "from models.cnn_geo import CNN_geo\n",
    "\n",
    "from debug_tools import data, train, visualize\n",
    "from utils import image\n",
    "import geo_transform as tps\n",
    "import CNNgeo_debug"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Read configuration file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('../overfit.json') as fp:\n",
    "    config = json.load(fp)\n",
    "split = 'val'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'exp_desc': '200507_regressor_filter_size_up', 'dataset_name': 'mini_imagenet', 'data_dir': '/home/files/datasets/mini_imagenet', 'image_shape': [64, 64, 3], 'model_name': 'CNNgeo', 'backbone': 'prototypical_network', 'data': {'method': 'synthesized_pair', 'tps_random_rate': 0.2, 'pad_ratio': 0.2}, 'ckpt': {'save_type': 'latest', 'max_to_keep': 10}, 'train': {'n_examples': 1, 'learning_rate': 0.0001, 'batch_size': 1, 'epochs': 200, 'print_step': 10}, 'val': {'n_examples': 1, 'batch_size': 1}, 'test': {'n_examples': -1, 'batch_size': 128}}\n"
     ]
    }
   ],
   "source": [
    "print(config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'n_examples': 1, 'learning_rate': 0.0001, 'batch_size': 1, 'epochs': 200, 'print_step': 10}\n"
     ]
    }
   ],
   "source": [
    "print(config['train'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "backbone :  prototypical_network\n",
      "n_examples :  1\n",
      "learning_rate :  0.0001\n",
      "batch_size :  1\n",
      "epoch num :  200\n"
     ]
    }
   ],
   "source": [
    "print(\"backbone : \", config['backbone'])\n",
    "print(\"n_examples : \", config['train']['n_examples'])\n",
    "print(\"learning_rate : \", config['train']['learning_rate'])\n",
    "print(\"batch_size : \", config['train']['batch_size'])\n",
    "print(\"epoch num : \", config['train']['epochs'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Train model on the config parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train dataset amount : 1\n",
      "val dataset amount : 1\n",
      "start of epoch 1\n",
      "Training loss (for one batch) at step 0: 0.43902745842933655\n",
      "Epoch 1, Loss: 0.43902745842933655, Val Loss: 0.5827353596687317\n",
      "end of epoch.\n",
      "start of epoch 2\n",
      "Training loss (for one batch) at step 0: 0.6366850733757019\n",
      "Epoch 2, Loss: 0.6366850733757019, Val Loss: 0.5820740461349487\n",
      "end of epoch.\n",
      "start of epoch 3\n",
      "Training loss (for one batch) at step 0: 0.5825507640838623\n",
      "Epoch 3, Loss: 0.5825507640838623, Val Loss: 0.5469998717308044\n",
      "end of epoch.\n",
      "start of epoch 4\n",
      "Training loss (for one batch) at step 0: 0.5997215509414673\n",
      "Epoch 4, Loss: 0.5997215509414673, Val Loss: 0.5166281461715698\n",
      "end of epoch.\n",
      "start of epoch 5\n",
      "Training loss (for one batch) at step 0: 0.693054735660553\n",
      "Epoch 5, Loss: 0.693054735660553, Val Loss: 0.6074742078781128\n",
      "end of epoch.\n",
      "start of epoch 6\n",
      "Training loss (for one batch) at step 0: 0.5771002769470215\n",
      "Epoch 6, Loss: 0.5771002769470215, Val Loss: 0.5495776534080505\n",
      "end of epoch.\n",
      "start of epoch 7\n",
      "Training loss (for one batch) at step 0: 0.47373002767562866\n",
      "Epoch 7, Loss: 0.47373002767562866, Val Loss: 0.4683365523815155\n",
      "end of epoch.\n",
      "start of epoch 8\n",
      "Training loss (for one batch) at step 0: 0.4825614392757416\n",
      "Epoch 8, Loss: 0.4825614392757416, Val Loss: 0.43670403957366943\n",
      "end of epoch.\n",
      "start of epoch 9\n",
      "Training loss (for one batch) at step 0: 0.43629616498947144\n",
      "Epoch 9, Loss: 0.43629616498947144, Val Loss: 0.5164625644683838\n",
      "end of epoch.\n",
      "start of epoch 10\n",
      "Training loss (for one batch) at step 0: 0.5255681872367859\n",
      "Epoch 10, Loss: 0.5255681872367859, Val Loss: 0.576608419418335\n",
      "end of epoch.\n",
      "start of epoch 11\n",
      "Training loss (for one batch) at step 0: 0.5440493822097778\n",
      "Epoch 11, Loss: 0.5440493822097778, Val Loss: 0.5349236130714417\n",
      "end of epoch.\n",
      "start of epoch 12\n",
      "Training loss (for one batch) at step 0: 0.5173596739768982\n",
      "Epoch 12, Loss: 0.5173596739768982, Val Loss: 0.45058682560920715\n",
      "end of epoch.\n",
      "start of epoch 13\n",
      "Training loss (for one batch) at step 0: 0.4627838730812073\n",
      "Epoch 13, Loss: 0.4627838730812073, Val Loss: 0.5170693397521973\n",
      "end of epoch.\n",
      "start of epoch 14\n",
      "Training loss (for one batch) at step 0: 0.5896347165107727\n",
      "Epoch 14, Loss: 0.5896347165107727, Val Loss: 0.43276238441467285\n",
      "end of epoch.\n",
      "start of epoch 15\n",
      "Training loss (for one batch) at step 0: 0.5545815825462341\n",
      "Epoch 15, Loss: 0.5545815825462341, Val Loss: 0.4912371337413788\n",
      "end of epoch.\n",
      "start of epoch 16\n",
      "Training loss (for one batch) at step 0: 0.532599925994873\n",
      "Epoch 16, Loss: 0.532599925994873, Val Loss: 0.47356680035591125\n",
      "end of epoch.\n",
      "start of epoch 17\n",
      "Training loss (for one batch) at step 0: 0.5716674327850342\n",
      "Epoch 17, Loss: 0.5716674327850342, Val Loss: 0.4604819118976593\n",
      "end of epoch.\n",
      "start of epoch 18\n",
      "Training loss (for one batch) at step 0: 0.4724253714084625\n",
      "Epoch 18, Loss: 0.4724253714084625, Val Loss: 0.46244579553604126\n",
      "end of epoch.\n",
      "start of epoch 19\n",
      "Training loss (for one batch) at step 0: 0.5099226236343384\n",
      "Epoch 19, Loss: 0.5099226236343384, Val Loss: 0.5108639597892761\n",
      "end of epoch.\n",
      "start of epoch 20\n",
      "Training loss (for one batch) at step 0: 0.43555113673210144\n",
      "Epoch 20, Loss: 0.43555113673210144, Val Loss: 0.4564078152179718\n",
      "end of epoch.\n",
      "start of epoch 21\n",
      "Training loss (for one batch) at step 0: 0.46616923809051514\n",
      "Epoch 21, Loss: 0.46616923809051514, Val Loss: 0.4556156396865845\n",
      "end of epoch.\n",
      "start of epoch 22\n",
      "Training loss (for one batch) at step 0: 0.4560937285423279\n",
      "Epoch 22, Loss: 0.4560937285423279, Val Loss: 0.5107172131538391\n",
      "end of epoch.\n",
      "start of epoch 23\n",
      "Training loss (for one batch) at step 0: 0.35416629910469055\n",
      "Epoch 23, Loss: 0.35416629910469055, Val Loss: 0.4531729519367218\n",
      "end of epoch.\n",
      "start of epoch 24\n",
      "Training loss (for one batch) at step 0: 0.357946515083313\n",
      "Epoch 24, Loss: 0.357946515083313, Val Loss: 0.46611207723617554\n",
      "end of epoch.\n",
      "start of epoch 25\n",
      "Training loss (for one batch) at step 0: 0.47701171040534973\n",
      "Epoch 25, Loss: 0.47701171040534973, Val Loss: 0.4735853970050812\n",
      "end of epoch.\n",
      "start of epoch 26\n",
      "Training loss (for one batch) at step 0: 0.4817088544368744\n",
      "Epoch 26, Loss: 0.4817088544368744, Val Loss: 0.47542843222618103\n",
      "end of epoch.\n",
      "start of epoch 27\n",
      "Training loss (for one batch) at step 0: 0.4007541537284851\n",
      "Epoch 27, Loss: 0.4007541537284851, Val Loss: 0.4977896511554718\n",
      "end of epoch.\n",
      "start of epoch 28\n",
      "Training loss (for one batch) at step 0: 0.6214612722396851\n",
      "Epoch 28, Loss: 0.6214612722396851, Val Loss: 0.5135418772697449\n",
      "end of epoch.\n",
      "start of epoch 29\n",
      "Training loss (for one batch) at step 0: 0.42934513092041016\n",
      "Epoch 29, Loss: 0.42934513092041016, Val Loss: 0.4523440897464752\n",
      "end of epoch.\n",
      "start of epoch 30\n",
      "Training loss (for one batch) at step 0: 0.4665832221508026\n",
      "Epoch 30, Loss: 0.4665832221508026, Val Loss: 0.41822075843811035\n",
      "end of epoch.\n",
      "start of epoch 31\n",
      "Training loss (for one batch) at step 0: 0.487364798784256\n",
      "Epoch 31, Loss: 0.487364798784256, Val Loss: 0.42433008551597595\n",
      "end of epoch.\n",
      "start of epoch 32\n",
      "Training loss (for one batch) at step 0: 0.5436000227928162\n",
      "Epoch 32, Loss: 0.5436000227928162, Val Loss: 0.42627575993537903\n",
      "end of epoch.\n",
      "start of epoch 33\n",
      "Training loss (for one batch) at step 0: 0.5012146234512329\n",
      "Epoch 33, Loss: 0.5012146234512329, Val Loss: 0.6023399233818054\n",
      "end of epoch.\n",
      "start of epoch 34\n",
      "Training loss (for one batch) at step 0: 0.5309406518936157\n",
      "Epoch 34, Loss: 0.5309406518936157, Val Loss: 0.5179280042648315\n",
      "end of epoch.\n",
      "start of epoch 35\n",
      "Training loss (for one batch) at step 0: 0.5092430710792542\n",
      "Epoch 35, Loss: 0.5092430710792542, Val Loss: 0.4506359100341797\n",
      "end of epoch.\n",
      "start of epoch 36\n",
      "Training loss (for one batch) at step 0: 0.4240350127220154\n",
      "Epoch 36, Loss: 0.4240350127220154, Val Loss: 0.5696688294410706\n",
      "end of epoch.\n",
      "start of epoch 37\n",
      "Training loss (for one batch) at step 0: 0.5494002103805542\n",
      "Epoch 37, Loss: 0.5494002103805542, Val Loss: 0.5300684571266174\n",
      "end of epoch.\n",
      "start of epoch 38\n",
      "Training loss (for one batch) at step 0: 0.4868069291114807\n",
      "Epoch 38, Loss: 0.4868069291114807, Val Loss: 0.4399300515651703\n",
      "end of epoch.\n",
      "start of epoch 39\n",
      "Training loss (for one batch) at step 0: 0.5433698296546936\n",
      "Epoch 39, Loss: 0.5433698296546936, Val Loss: 0.5746111869812012\n",
      "end of epoch.\n",
      "start of epoch 40\n",
      "Training loss (for one batch) at step 0: 0.4977445900440216\n",
      "Epoch 40, Loss: 0.4977445900440216, Val Loss: 0.5192562341690063\n",
      "end of epoch.\n",
      "start of epoch 41\n",
      "Training loss (for one batch) at step 0: 0.48933184146881104\n",
      "Epoch 41, Loss: 0.48933184146881104, Val Loss: 0.5756078362464905\n",
      "end of epoch.\n",
      "start of epoch 42\n",
      "Training loss (for one batch) at step 0: 0.3503595292568207\n",
      "Epoch 42, Loss: 0.3503595292568207, Val Loss: 0.5091153979301453\n",
      "end of epoch.\n",
      "start of epoch 43\n",
      "Training loss (for one batch) at step 0: 0.45660603046417236\n",
      "Epoch 43, Loss: 0.45660603046417236, Val Loss: 0.48571276664733887\n",
      "end of epoch.\n",
      "start of epoch 44\n",
      "Training loss (for one batch) at step 0: 0.47132885456085205\n",
      "Epoch 44, Loss: 0.47132885456085205, Val Loss: 0.5314492583274841\n",
      "end of epoch.\n",
      "start of epoch 45\n",
      "Training loss (for one batch) at step 0: 0.40036919713020325\n",
      "Epoch 45, Loss: 0.40036919713020325, Val Loss: 0.3984645903110504\n",
      "end of epoch.\n",
      "start of epoch 46\n",
      "Training loss (for one batch) at step 0: 0.39071232080459595\n",
      "Epoch 46, Loss: 0.39071232080459595, Val Loss: 0.5186546444892883\n",
      "end of epoch.\n",
      "start of epoch 47\n",
      "Training loss (for one batch) at step 0: 0.4674946665763855\n",
      "Epoch 47, Loss: 0.4674946665763855, Val Loss: 0.5041317343711853\n",
      "end of epoch.\n",
      "start of epoch 48\n",
      "Training loss (for one batch) at step 0: 0.389235258102417\n",
      "Epoch 48, Loss: 0.389235258102417, Val Loss: 0.5111089944839478\n",
      "end of epoch.\n",
      "start of epoch 49\n",
      "Training loss (for one batch) at step 0: 0.5245325565338135\n",
      "Epoch 49, Loss: 0.5245325565338135, Val Loss: 0.44669002294540405\n",
      "end of epoch.\n",
      "start of epoch 50\n",
      "Training loss (for one batch) at step 0: 0.5620603561401367\n",
      "Epoch 50, Loss: 0.5620603561401367, Val Loss: 0.4771091043949127\n",
      "end of epoch.\n",
      "start of epoch 51\n",
      "Training loss (for one batch) at step 0: 0.49361804127693176\n",
      "Epoch 51, Loss: 0.49361804127693176, Val Loss: 0.4541855454444885\n",
      "end of epoch.\n",
      "start of epoch 52\n",
      "Training loss (for one batch) at step 0: 0.46197807788848877\n",
      "Epoch 52, Loss: 0.46197807788848877, Val Loss: 0.4945034980773926\n",
      "end of epoch.\n",
      "start of epoch 53\n",
      "Training loss (for one batch) at step 0: 0.5565651059150696\n",
      "Epoch 53, Loss: 0.5565651059150696, Val Loss: 0.4591946005821228\n",
      "end of epoch.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "start of epoch 54\n",
      "Training loss (for one batch) at step 0: 0.45287981629371643\n",
      "Epoch 54, Loss: 0.45287981629371643, Val Loss: 0.5369423627853394\n",
      "end of epoch.\n",
      "start of epoch 55\n",
      "Training loss (for one batch) at step 0: 0.4947085976600647\n",
      "Epoch 55, Loss: 0.4947085976600647, Val Loss: 0.41329246759414673\n",
      "end of epoch.\n",
      "start of epoch 56\n",
      "Training loss (for one batch) at step 0: 0.5097077488899231\n",
      "Epoch 56, Loss: 0.5097077488899231, Val Loss: 0.46729469299316406\n",
      "end of epoch.\n",
      "start of epoch 57\n",
      "Training loss (for one batch) at step 0: 0.580666184425354\n",
      "Epoch 57, Loss: 0.580666184425354, Val Loss: 0.4069864749908447\n",
      "end of epoch.\n",
      "start of epoch 58\n",
      "Training loss (for one batch) at step 0: 0.5493994355201721\n",
      "Epoch 58, Loss: 0.5493994355201721, Val Loss: 0.47990331053733826\n",
      "end of epoch.\n",
      "start of epoch 59\n",
      "Training loss (for one batch) at step 0: 0.45678627490997314\n",
      "Epoch 59, Loss: 0.45678627490997314, Val Loss: 0.5390716195106506\n",
      "end of epoch.\n",
      "start of epoch 60\n",
      "Training loss (for one batch) at step 0: 0.5771216750144958\n",
      "Epoch 60, Loss: 0.5771216750144958, Val Loss: 0.47866928577423096\n",
      "end of epoch.\n",
      "start of epoch 61\n",
      "Training loss (for one batch) at step 0: 0.5619413256645203\n",
      "Epoch 61, Loss: 0.5619413256645203, Val Loss: 0.4741513729095459\n",
      "end of epoch.\n",
      "start of epoch 62\n",
      "Training loss (for one batch) at step 0: 0.5709774494171143\n",
      "Epoch 62, Loss: 0.5709774494171143, Val Loss: 0.6078897714614868\n",
      "end of epoch.\n",
      "start of epoch 63\n",
      "Training loss (for one batch) at step 0: 0.462677538394928\n",
      "Epoch 63, Loss: 0.462677538394928, Val Loss: 0.5288618206977844\n",
      "end of epoch.\n",
      "start of epoch 64\n",
      "Training loss (for one batch) at step 0: 0.5302935838699341\n",
      "Epoch 64, Loss: 0.5302935838699341, Val Loss: 0.4148883819580078\n",
      "end of epoch.\n",
      "start of epoch 65\n",
      "Training loss (for one batch) at step 0: 0.4469018876552582\n",
      "Epoch 65, Loss: 0.4469018876552582, Val Loss: 0.4442751407623291\n",
      "end of epoch.\n",
      "start of epoch 66\n",
      "Training loss (for one batch) at step 0: 0.5228754878044128\n",
      "Epoch 66, Loss: 0.5228754878044128, Val Loss: 0.3969653248786926\n",
      "end of epoch.\n",
      "start of epoch 67\n",
      "Training loss (for one batch) at step 0: 0.572143018245697\n",
      "Epoch 67, Loss: 0.572143018245697, Val Loss: 0.36314618587493896\n",
      "end of epoch.\n",
      "start of epoch 68\n",
      "Training loss (for one batch) at step 0: 0.5394014120101929\n",
      "Epoch 68, Loss: 0.5394014120101929, Val Loss: 0.4996417164802551\n",
      "end of epoch.\n",
      "start of epoch 69\n",
      "Training loss (for one batch) at step 0: 0.5114014744758606\n",
      "Epoch 69, Loss: 0.5114014744758606, Val Loss: 0.518428385257721\n",
      "end of epoch.\n",
      "start of epoch 70\n",
      "Training loss (for one batch) at step 0: 0.5030130743980408\n",
      "Epoch 70, Loss: 0.5030130743980408, Val Loss: 0.5576179027557373\n",
      "end of epoch.\n",
      "start of epoch 71\n",
      "Training loss (for one batch) at step 0: 0.4875876009464264\n",
      "Epoch 71, Loss: 0.4875876009464264, Val Loss: 0.41538721323013306\n",
      "end of epoch.\n",
      "start of epoch 72\n",
      "Training loss (for one batch) at step 0: 0.4464266300201416\n",
      "Epoch 72, Loss: 0.4464266300201416, Val Loss: 0.4088311791419983\n",
      "end of epoch.\n",
      "start of epoch 73\n",
      "Training loss (for one batch) at step 0: 0.517137348651886\n",
      "Epoch 73, Loss: 0.517137348651886, Val Loss: 0.43714913725852966\n",
      "end of epoch.\n",
      "start of epoch 74\n",
      "Training loss (for one batch) at step 0: 0.4354715049266815\n",
      "Epoch 74, Loss: 0.4354715049266815, Val Loss: 0.4660329520702362\n",
      "end of epoch.\n",
      "start of epoch 75\n",
      "Training loss (for one batch) at step 0: 0.4402250647544861\n",
      "Epoch 75, Loss: 0.4402250647544861, Val Loss: 0.48434147238731384\n",
      "end of epoch.\n",
      "start of epoch 76\n",
      "Training loss (for one batch) at step 0: 0.5970737338066101\n",
      "Epoch 76, Loss: 0.5970737338066101, Val Loss: 0.3532908260822296\n",
      "end of epoch.\n",
      "start of epoch 77\n",
      "Training loss (for one batch) at step 0: 0.5373247861862183\n",
      "Epoch 77, Loss: 0.5373247861862183, Val Loss: 0.6307569742202759\n",
      "end of epoch.\n",
      "start of epoch 78\n",
      "Training loss (for one batch) at step 0: 0.5568571090698242\n",
      "Epoch 78, Loss: 0.5568571090698242, Val Loss: 0.4702351987361908\n",
      "end of epoch.\n",
      "start of epoch 79\n",
      "Training loss (for one batch) at step 0: 0.46420109272003174\n",
      "Epoch 79, Loss: 0.46420109272003174, Val Loss: 0.432169646024704\n",
      "end of epoch.\n",
      "start of epoch 80\n",
      "Training loss (for one batch) at step 0: 0.46890655159950256\n",
      "Epoch 80, Loss: 0.46890655159950256, Val Loss: 0.5597058534622192\n",
      "end of epoch.\n",
      "start of epoch 81\n",
      "Training loss (for one batch) at step 0: 0.5398284196853638\n",
      "Epoch 81, Loss: 0.5398284196853638, Val Loss: 0.4512825310230255\n",
      "end of epoch.\n",
      "start of epoch 82\n",
      "Training loss (for one batch) at step 0: 0.4950273036956787\n",
      "Epoch 82, Loss: 0.4950273036956787, Val Loss: 0.5521008968353271\n",
      "end of epoch.\n",
      "start of epoch 83\n",
      "Training loss (for one batch) at step 0: 0.48285403847694397\n",
      "Epoch 83, Loss: 0.48285403847694397, Val Loss: 0.5060375928878784\n",
      "end of epoch.\n",
      "start of epoch 84\n",
      "Training loss (for one batch) at step 0: 0.5692945122718811\n",
      "Epoch 84, Loss: 0.5692945122718811, Val Loss: 0.4987693130970001\n",
      "end of epoch.\n",
      "start of epoch 85\n",
      "Training loss (for one batch) at step 0: 0.46682560443878174\n",
      "Epoch 85, Loss: 0.46682560443878174, Val Loss: 0.49508601427078247\n",
      "end of epoch.\n",
      "start of epoch 86\n",
      "Training loss (for one batch) at step 0: 0.5728468894958496\n",
      "Epoch 86, Loss: 0.5728468894958496, Val Loss: 0.3943217694759369\n",
      "end of epoch.\n",
      "start of epoch 87\n",
      "Training loss (for one batch) at step 0: 0.4201534688472748\n",
      "Epoch 87, Loss: 0.4201534688472748, Val Loss: 0.45797157287597656\n",
      "end of epoch.\n",
      "start of epoch 88\n",
      "Training loss (for one batch) at step 0: 0.49954572319984436\n",
      "Epoch 88, Loss: 0.49954572319984436, Val Loss: 0.5312100648880005\n",
      "end of epoch.\n",
      "start of epoch 89\n",
      "Training loss (for one batch) at step 0: 0.47001686692237854\n",
      "Epoch 89, Loss: 0.47001686692237854, Val Loss: 0.5098989605903625\n",
      "end of epoch.\n",
      "start of epoch 90\n",
      "Training loss (for one batch) at step 0: 0.41102030873298645\n",
      "Epoch 90, Loss: 0.41102030873298645, Val Loss: 0.49674689769744873\n",
      "end of epoch.\n",
      "start of epoch 91\n",
      "Training loss (for one batch) at step 0: 0.4283805787563324\n",
      "Epoch 91, Loss: 0.4283805787563324, Val Loss: 0.5674243569374084\n",
      "end of epoch.\n",
      "start of epoch 92\n",
      "Training loss (for one batch) at step 0: 0.4978751540184021\n",
      "Epoch 92, Loss: 0.4978751540184021, Val Loss: 0.45032772421836853\n",
      "end of epoch.\n",
      "start of epoch 93\n",
      "Training loss (for one batch) at step 0: 0.4605185091495514\n",
      "Epoch 93, Loss: 0.4605185091495514, Val Loss: 0.5949109792709351\n",
      "end of epoch.\n",
      "start of epoch 94\n",
      "Training loss (for one batch) at step 0: 0.4387991428375244\n",
      "Epoch 94, Loss: 0.4387991428375244, Val Loss: 0.53056401014328\n",
      "end of epoch.\n",
      "start of epoch 95\n",
      "Training loss (for one batch) at step 0: 0.3901731073856354\n",
      "Epoch 95, Loss: 0.3901731073856354, Val Loss: 0.44462597370147705\n",
      "end of epoch.\n",
      "start of epoch 96\n",
      "Training loss (for one batch) at step 0: 0.5194979310035706\n",
      "Epoch 96, Loss: 0.5194979310035706, Val Loss: 0.4496733546257019\n",
      "end of epoch.\n",
      "start of epoch 97\n",
      "Training loss (for one batch) at step 0: 0.4011702835559845\n",
      "Epoch 97, Loss: 0.4011702835559845, Val Loss: 0.4536875784397125\n",
      "end of epoch.\n",
      "start of epoch 98\n",
      "Training loss (for one batch) at step 0: 0.4896993637084961\n",
      "Epoch 98, Loss: 0.4896993637084961, Val Loss: 0.4678359627723694\n",
      "end of epoch.\n",
      "start of epoch 99\n",
      "Training loss (for one batch) at step 0: 0.5215643644332886\n",
      "Epoch 99, Loss: 0.5215643644332886, Val Loss: 0.537014901638031\n",
      "end of epoch.\n",
      "start of epoch 100\n",
      "Training loss (for one batch) at step 0: 0.4707207977771759\n",
      "Epoch 100, Loss: 0.4707207977771759, Val Loss: 0.4653102159500122\n",
      "end of epoch.\n",
      "start of epoch 101\n",
      "Training loss (for one batch) at step 0: 0.5024776458740234\n",
      "Epoch 101, Loss: 0.5024776458740234, Val Loss: 0.5042104125022888\n",
      "end of epoch.\n",
      "start of epoch 102\n",
      "Training loss (for one batch) at step 0: 0.5299534201622009\n",
      "Epoch 102, Loss: 0.5299534201622009, Val Loss: 0.581088662147522\n",
      "end of epoch.\n",
      "start of epoch 103\n",
      "Training loss (for one batch) at step 0: 0.4832981824874878\n",
      "Epoch 103, Loss: 0.4832981824874878, Val Loss: 0.5696130990982056\n",
      "end of epoch.\n",
      "start of epoch 104\n",
      "Training loss (for one batch) at step 0: 0.5264582633972168\n",
      "Epoch 104, Loss: 0.5264582633972168, Val Loss: 0.543929398059845\n",
      "end of epoch.\n",
      "start of epoch 105\n",
      "Training loss (for one batch) at step 0: 0.5949325561523438\n",
      "Epoch 105, Loss: 0.5949325561523438, Val Loss: 0.4754961133003235\n",
      "end of epoch.\n",
      "start of epoch 106\n",
      "Training loss (for one batch) at step 0: 0.43270355463027954\n",
      "Epoch 106, Loss: 0.43270355463027954, Val Loss: 0.49677300453186035\n",
      "end of epoch.\n",
      "start of epoch 107\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss (for one batch) at step 0: 0.5014543533325195\n",
      "Epoch 107, Loss: 0.5014543533325195, Val Loss: 0.5060539841651917\n",
      "end of epoch.\n",
      "start of epoch 108\n",
      "Training loss (for one batch) at step 0: 0.4728673994541168\n",
      "Epoch 108, Loss: 0.4728673994541168, Val Loss: 0.4759911000728607\n",
      "end of epoch.\n",
      "start of epoch 109\n",
      "Training loss (for one batch) at step 0: 0.45149749517440796\n",
      "Epoch 109, Loss: 0.45149749517440796, Val Loss: 0.5931161046028137\n",
      "end of epoch.\n",
      "start of epoch 110\n",
      "Training loss (for one batch) at step 0: 0.4221637547016144\n",
      "Epoch 110, Loss: 0.4221637547016144, Val Loss: 0.44368699193000793\n",
      "end of epoch.\n",
      "start of epoch 111\n",
      "Training loss (for one batch) at step 0: 0.45260652899742126\n",
      "Epoch 111, Loss: 0.45260652899742126, Val Loss: 0.5177887678146362\n",
      "end of epoch.\n",
      "start of epoch 112\n",
      "Training loss (for one batch) at step 0: 0.5156881809234619\n",
      "Epoch 112, Loss: 0.5156881809234619, Val Loss: 0.4487312436103821\n",
      "end of epoch.\n",
      "start of epoch 113\n",
      "Training loss (for one batch) at step 0: 0.5213077664375305\n",
      "Epoch 113, Loss: 0.5213077664375305, Val Loss: 0.3943643569946289\n",
      "end of epoch.\n",
      "start of epoch 114\n",
      "Training loss (for one batch) at step 0: 0.4319222569465637\n",
      "Epoch 114, Loss: 0.4319222569465637, Val Loss: 0.4178953170776367\n",
      "end of epoch.\n",
      "start of epoch 115\n",
      "Training loss (for one batch) at step 0: 0.4657941162586212\n",
      "Epoch 115, Loss: 0.4657941162586212, Val Loss: 0.3918744921684265\n",
      "end of epoch.\n",
      "start of epoch 116\n",
      "Training loss (for one batch) at step 0: 0.5168048143386841\n",
      "Epoch 116, Loss: 0.5168048143386841, Val Loss: 0.5862359404563904\n",
      "end of epoch.\n",
      "start of epoch 117\n",
      "Training loss (for one batch) at step 0: 0.5110245943069458\n",
      "Epoch 117, Loss: 0.5110245943069458, Val Loss: 0.4098794758319855\n",
      "end of epoch.\n",
      "start of epoch 118\n",
      "Training loss (for one batch) at step 0: 0.4638950526714325\n",
      "Epoch 118, Loss: 0.4638950526714325, Val Loss: 0.43216773867607117\n",
      "end of epoch.\n",
      "start of epoch 119\n",
      "Training loss (for one batch) at step 0: 0.4182480573654175\n",
      "Epoch 119, Loss: 0.4182480573654175, Val Loss: 0.5503790974617004\n",
      "end of epoch.\n",
      "start of epoch 120\n",
      "Training loss (for one batch) at step 0: 0.4913565516471863\n",
      "Epoch 120, Loss: 0.4913565516471863, Val Loss: 0.5624380707740784\n",
      "end of epoch.\n",
      "start of epoch 121\n",
      "Training loss (for one batch) at step 0: 0.516906201839447\n",
      "Epoch 121, Loss: 0.516906201839447, Val Loss: 0.4505915641784668\n",
      "end of epoch.\n",
      "start of epoch 122\n",
      "Training loss (for one batch) at step 0: 0.5001270174980164\n",
      "Epoch 122, Loss: 0.5001270174980164, Val Loss: 0.4541977643966675\n",
      "end of epoch.\n",
      "start of epoch 123\n",
      "Training loss (for one batch) at step 0: 0.5791006684303284\n",
      "Epoch 123, Loss: 0.5791006684303284, Val Loss: 0.4400692582130432\n",
      "end of epoch.\n",
      "start of epoch 124\n",
      "Training loss (for one batch) at step 0: 0.44455331563949585\n",
      "Epoch 124, Loss: 0.44455331563949585, Val Loss: 0.5130704045295715\n",
      "end of epoch.\n",
      "start of epoch 125\n",
      "Training loss (for one batch) at step 0: 0.4632798731327057\n",
      "Epoch 125, Loss: 0.4632798731327057, Val Loss: 0.49257659912109375\n",
      "end of epoch.\n",
      "start of epoch 126\n",
      "Training loss (for one batch) at step 0: 0.443040668964386\n",
      "Epoch 126, Loss: 0.443040668964386, Val Loss: 0.5325658321380615\n",
      "end of epoch.\n",
      "start of epoch 127\n",
      "Training loss (for one batch) at step 0: 0.5215174555778503\n",
      "Epoch 127, Loss: 0.5215174555778503, Val Loss: 0.4862079918384552\n",
      "end of epoch.\n",
      "start of epoch 128\n",
      "Training loss (for one batch) at step 0: 0.5038790106773376\n",
      "Epoch 128, Loss: 0.5038790106773376, Val Loss: 0.38146549463272095\n",
      "end of epoch.\n",
      "start of epoch 129\n",
      "Training loss (for one batch) at step 0: 0.48047950863838196\n",
      "Epoch 129, Loss: 0.48047950863838196, Val Loss: 0.46073782444000244\n",
      "end of epoch.\n",
      "start of epoch 130\n",
      "Training loss (for one batch) at step 0: 0.44793611764907837\n",
      "Epoch 130, Loss: 0.44793611764907837, Val Loss: 0.46042224764823914\n",
      "end of epoch.\n",
      "start of epoch 131\n",
      "Training loss (for one batch) at step 0: 0.45762696862220764\n",
      "Epoch 131, Loss: 0.45762696862220764, Val Loss: 0.4820408523082733\n",
      "end of epoch.\n",
      "start of epoch 132\n",
      "Training loss (for one batch) at step 0: 0.5183168649673462\n",
      "Epoch 132, Loss: 0.5183168649673462, Val Loss: 0.45445120334625244\n",
      "end of epoch.\n",
      "start of epoch 133\n",
      "Training loss (for one batch) at step 0: 0.5426384806632996\n",
      "Epoch 133, Loss: 0.5426384806632996, Val Loss: 0.46429941058158875\n",
      "end of epoch.\n",
      "start of epoch 134\n",
      "Training loss (for one batch) at step 0: 0.39315375685691833\n",
      "Epoch 134, Loss: 0.39315375685691833, Val Loss: 0.5110480189323425\n",
      "end of epoch.\n",
      "start of epoch 135\n",
      "Training loss (for one batch) at step 0: 0.5844286680221558\n",
      "Epoch 135, Loss: 0.5844286680221558, Val Loss: 0.5775271058082581\n",
      "end of epoch.\n",
      "start of epoch 136\n",
      "Training loss (for one batch) at step 0: 0.4538149833679199\n",
      "Epoch 136, Loss: 0.4538149833679199, Val Loss: 0.544631838798523\n",
      "end of epoch.\n",
      "start of epoch 137\n",
      "Training loss (for one batch) at step 0: 0.4354124069213867\n",
      "Epoch 137, Loss: 0.4354124069213867, Val Loss: 0.5291268229484558\n",
      "end of epoch.\n",
      "start of epoch 138\n",
      "Training loss (for one batch) at step 0: 0.49396172165870667\n",
      "Epoch 138, Loss: 0.49396172165870667, Val Loss: 0.42556270956993103\n",
      "end of epoch.\n",
      "start of epoch 139\n",
      "Training loss (for one batch) at step 0: 0.5226142406463623\n",
      "Epoch 139, Loss: 0.5226142406463623, Val Loss: 0.5502382516860962\n",
      "end of epoch.\n",
      "start of epoch 140\n",
      "Training loss (for one batch) at step 0: 0.5315974950790405\n",
      "Epoch 140, Loss: 0.5315974950790405, Val Loss: 0.529771625995636\n",
      "end of epoch.\n",
      "start of epoch 141\n",
      "Training loss (for one batch) at step 0: 0.5459620356559753\n",
      "Epoch 141, Loss: 0.5459620356559753, Val Loss: 0.5353810787200928\n",
      "end of epoch.\n",
      "start of epoch 142\n",
      "Training loss (for one batch) at step 0: 0.48085588216781616\n",
      "Epoch 142, Loss: 0.48085588216781616, Val Loss: 0.4926302433013916\n",
      "end of epoch.\n",
      "start of epoch 143\n",
      "Training loss (for one batch) at step 0: 0.46881750226020813\n",
      "Epoch 143, Loss: 0.46881750226020813, Val Loss: 0.4738389849662781\n",
      "end of epoch.\n",
      "start of epoch 144\n",
      "Training loss (for one batch) at step 0: 0.4402118921279907\n",
      "Epoch 144, Loss: 0.4402118921279907, Val Loss: 0.4854707717895508\n",
      "end of epoch.\n",
      "start of epoch 145\n",
      "Training loss (for one batch) at step 0: 0.46417975425720215\n",
      "Epoch 145, Loss: 0.46417975425720215, Val Loss: 0.4797278642654419\n",
      "end of epoch.\n",
      "start of epoch 146\n",
      "Training loss (for one batch) at step 0: 0.491179496049881\n",
      "Epoch 146, Loss: 0.491179496049881, Val Loss: 0.3497605621814728\n",
      "end of epoch.\n",
      "start of epoch 147\n",
      "Training loss (for one batch) at step 0: 0.4592375159263611\n",
      "Epoch 147, Loss: 0.4592375159263611, Val Loss: 0.5115609169006348\n",
      "end of epoch.\n",
      "start of epoch 148\n",
      "Training loss (for one batch) at step 0: 0.5528627634048462\n",
      "Epoch 148, Loss: 0.5528627634048462, Val Loss: 0.5036245584487915\n",
      "end of epoch.\n",
      "start of epoch 149\n",
      "Training loss (for one batch) at step 0: 0.47698378562927246\n",
      "Epoch 149, Loss: 0.47698378562927246, Val Loss: 0.46953120827674866\n",
      "end of epoch.\n",
      "start of epoch 150\n",
      "Training loss (for one batch) at step 0: 0.5828742980957031\n",
      "Epoch 150, Loss: 0.5828742980957031, Val Loss: 0.5925261974334717\n",
      "end of epoch.\n",
      "start of epoch 151\n",
      "Training loss (for one batch) at step 0: 0.43766161799430847\n",
      "Epoch 151, Loss: 0.43766161799430847, Val Loss: 0.4975365996360779\n",
      "end of epoch.\n",
      "start of epoch 152\n",
      "Training loss (for one batch) at step 0: 0.5018948316574097\n",
      "Epoch 152, Loss: 0.5018948316574097, Val Loss: 0.4419914782047272\n",
      "end of epoch.\n",
      "start of epoch 153\n",
      "Training loss (for one batch) at step 0: 0.4528547525405884\n",
      "Epoch 153, Loss: 0.4528547525405884, Val Loss: 0.5409974455833435\n",
      "end of epoch.\n",
      "start of epoch 154\n",
      "Training loss (for one batch) at step 0: 0.48548462986946106\n",
      "Epoch 154, Loss: 0.48548462986946106, Val Loss: 0.4137077033519745\n",
      "end of epoch.\n",
      "start of epoch 155\n",
      "Training loss (for one batch) at step 0: 0.5588396191596985\n",
      "Epoch 155, Loss: 0.5588396191596985, Val Loss: 0.5879209637641907\n",
      "end of epoch.\n",
      "start of epoch 156\n",
      "Training loss (for one batch) at step 0: 0.4773223102092743\n",
      "Epoch 156, Loss: 0.4773223102092743, Val Loss: 0.5496983528137207\n",
      "end of epoch.\n",
      "start of epoch 157\n",
      "Training loss (for one batch) at step 0: 0.47742462158203125\n",
      "Epoch 157, Loss: 0.47742462158203125, Val Loss: 0.5195779204368591\n",
      "end of epoch.\n",
      "start of epoch 158\n",
      "Training loss (for one batch) at step 0: 0.529188334941864\n",
      "Epoch 158, Loss: 0.529188334941864, Val Loss: 0.47860080003738403\n",
      "end of epoch.\n",
      "start of epoch 159\n",
      "Training loss (for one batch) at step 0: 0.3509855270385742\n",
      "Epoch 159, Loss: 0.3509855270385742, Val Loss: 0.4958791136741638\n",
      "end of epoch.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "start of epoch 160\n",
      "Training loss (for one batch) at step 0: 0.500227689743042\n",
      "Epoch 160, Loss: 0.500227689743042, Val Loss: 0.45620670914649963\n",
      "end of epoch.\n",
      "start of epoch 161\n",
      "Training loss (for one batch) at step 0: 0.4913319945335388\n",
      "Epoch 161, Loss: 0.4913319945335388, Val Loss: 0.5304445028305054\n",
      "end of epoch.\n",
      "start of epoch 162\n",
      "Training loss (for one batch) at step 0: 0.47823089361190796\n",
      "Epoch 162, Loss: 0.47823089361190796, Val Loss: 0.4983280897140503\n",
      "end of epoch.\n",
      "start of epoch 163\n",
      "Training loss (for one batch) at step 0: 0.44208139181137085\n",
      "Epoch 163, Loss: 0.44208139181137085, Val Loss: 0.5725592970848083\n",
      "end of epoch.\n",
      "start of epoch 164\n",
      "Training loss (for one batch) at step 0: 0.5530843138694763\n",
      "Epoch 164, Loss: 0.5530843138694763, Val Loss: 0.550096333026886\n",
      "end of epoch.\n",
      "start of epoch 165\n",
      "Training loss (for one batch) at step 0: 0.4396674335002899\n",
      "Epoch 165, Loss: 0.4396674335002899, Val Loss: 0.4560273587703705\n",
      "end of epoch.\n",
      "start of epoch 166\n",
      "Training loss (for one batch) at step 0: 0.4320494830608368\n",
      "Epoch 166, Loss: 0.4320494830608368, Val Loss: 0.49572834372520447\n",
      "end of epoch.\n",
      "start of epoch 167\n",
      "Training loss (for one batch) at step 0: 0.5024706721305847\n",
      "Epoch 167, Loss: 0.5024706721305847, Val Loss: 0.4632038176059723\n",
      "end of epoch.\n",
      "start of epoch 168\n",
      "Training loss (for one batch) at step 0: 0.5492572784423828\n",
      "Epoch 168, Loss: 0.5492572784423828, Val Loss: 0.46095335483551025\n",
      "end of epoch.\n",
      "start of epoch 169\n",
      "Training loss (for one batch) at step 0: 0.49564382433891296\n",
      "Epoch 169, Loss: 0.49564382433891296, Val Loss: 0.48916494846343994\n",
      "end of epoch.\n",
      "start of epoch 170\n",
      "Training loss (for one batch) at step 0: 0.4697498083114624\n",
      "Epoch 170, Loss: 0.4697498083114624, Val Loss: 0.5497353672981262\n",
      "end of epoch.\n",
      "start of epoch 171\n",
      "Training loss (for one batch) at step 0: 0.5128835439682007\n",
      "Epoch 171, Loss: 0.5128835439682007, Val Loss: 0.5297508239746094\n",
      "end of epoch.\n",
      "start of epoch 172\n",
      "Training loss (for one batch) at step 0: 0.5420776009559631\n",
      "Epoch 172, Loss: 0.5420776009559631, Val Loss: 0.4583689272403717\n",
      "end of epoch.\n",
      "start of epoch 173\n",
      "Training loss (for one batch) at step 0: 0.5420240759849548\n",
      "Epoch 173, Loss: 0.5420240759849548, Val Loss: 0.48158299922943115\n",
      "end of epoch.\n",
      "start of epoch 174\n",
      "Training loss (for one batch) at step 0: 0.49218276143074036\n",
      "Epoch 174, Loss: 0.49218276143074036, Val Loss: 0.4892013669013977\n",
      "end of epoch.\n",
      "start of epoch 175\n",
      "Training loss (for one batch) at step 0: 0.4821133315563202\n",
      "Epoch 175, Loss: 0.4821133315563202, Val Loss: 0.44175899028778076\n",
      "end of epoch.\n",
      "start of epoch 176\n",
      "Training loss (for one batch) at step 0: 0.4957978129386902\n",
      "Epoch 176, Loss: 0.4957978129386902, Val Loss: 0.41188570857048035\n",
      "end of epoch.\n",
      "start of epoch 177\n",
      "Training loss (for one batch) at step 0: 0.5019494295120239\n",
      "Epoch 177, Loss: 0.5019494295120239, Val Loss: 0.5189571976661682\n",
      "end of epoch.\n",
      "start of epoch 178\n",
      "Training loss (for one batch) at step 0: 0.38035574555397034\n",
      "Epoch 178, Loss: 0.38035574555397034, Val Loss: 0.44738706946372986\n",
      "end of epoch.\n",
      "start of epoch 179\n",
      "Training loss (for one batch) at step 0: 0.412549763917923\n",
      "Epoch 179, Loss: 0.412549763917923, Val Loss: 0.49411630630493164\n",
      "end of epoch.\n",
      "start of epoch 180\n",
      "Training loss (for one batch) at step 0: 0.4560427963733673\n",
      "Epoch 180, Loss: 0.4560427963733673, Val Loss: 0.42003071308135986\n",
      "end of epoch.\n",
      "start of epoch 181\n",
      "Training loss (for one batch) at step 0: 0.4950125813484192\n",
      "Epoch 181, Loss: 0.4950125813484192, Val Loss: 0.4676395058631897\n",
      "end of epoch.\n",
      "start of epoch 182\n",
      "Training loss (for one batch) at step 0: 0.46368536353111267\n",
      "Epoch 182, Loss: 0.46368536353111267, Val Loss: 0.4595062732696533\n",
      "end of epoch.\n",
      "start of epoch 183\n",
      "Training loss (for one batch) at step 0: 0.43864819407463074\n",
      "Epoch 183, Loss: 0.43864819407463074, Val Loss: 0.5499395132064819\n",
      "end of epoch.\n",
      "start of epoch 184\n",
      "Training loss (for one batch) at step 0: 0.44636714458465576\n",
      "Epoch 184, Loss: 0.44636714458465576, Val Loss: 0.4821222722530365\n",
      "end of epoch.\n",
      "start of epoch 185\n",
      "Training loss (for one batch) at step 0: 0.5950595736503601\n",
      "Epoch 185, Loss: 0.5950595736503601, Val Loss: 0.5322311520576477\n",
      "end of epoch.\n",
      "start of epoch 186\n",
      "Training loss (for one batch) at step 0: 0.48587578535079956\n",
      "Epoch 186, Loss: 0.48587578535079956, Val Loss: 0.5061637163162231\n",
      "end of epoch.\n",
      "start of epoch 187\n",
      "Training loss (for one batch) at step 0: 0.45997968316078186\n",
      "Epoch 187, Loss: 0.45997968316078186, Val Loss: 0.4413011372089386\n",
      "end of epoch.\n",
      "start of epoch 188\n",
      "Training loss (for one batch) at step 0: 0.4214109480381012\n",
      "Epoch 188, Loss: 0.4214109480381012, Val Loss: 0.5305286049842834\n",
      "end of epoch.\n",
      "start of epoch 189\n",
      "Training loss (for one batch) at step 0: 0.4346986413002014\n",
      "Epoch 189, Loss: 0.4346986413002014, Val Loss: 0.5546144247055054\n",
      "end of epoch.\n",
      "start of epoch 190\n",
      "Training loss (for one batch) at step 0: 0.5391134023666382\n",
      "Epoch 190, Loss: 0.5391134023666382, Val Loss: 0.5462009310722351\n",
      "end of epoch.\n",
      "start of epoch 191\n",
      "Training loss (for one batch) at step 0: 0.42604756355285645\n",
      "Epoch 191, Loss: 0.42604756355285645, Val Loss: 0.4690019488334656\n",
      "end of epoch.\n",
      "start of epoch 192\n",
      "Training loss (for one batch) at step 0: 0.45922037959098816\n",
      "Epoch 192, Loss: 0.45922037959098816, Val Loss: 0.5138146877288818\n",
      "end of epoch.\n",
      "start of epoch 193\n",
      "Training loss (for one batch) at step 0: 0.5329889059066772\n",
      "Epoch 193, Loss: 0.5329889059066772, Val Loss: 0.4945200979709625\n",
      "end of epoch.\n",
      "start of epoch 194\n",
      "Training loss (for one batch) at step 0: 0.4799555242061615\n",
      "Epoch 194, Loss: 0.4799555242061615, Val Loss: 0.5439692735671997\n",
      "end of epoch.\n",
      "start of epoch 195\n",
      "Training loss (for one batch) at step 0: 0.5068517923355103\n",
      "Epoch 195, Loss: 0.5068517923355103, Val Loss: 0.5874099731445312\n",
      "end of epoch.\n",
      "start of epoch 196\n",
      "Training loss (for one batch) at step 0: 0.44482725858688354\n",
      "Epoch 196, Loss: 0.44482725858688354, Val Loss: 0.5220542550086975\n",
      "end of epoch.\n",
      "start of epoch 197\n",
      "Training loss (for one batch) at step 0: 0.4740114212036133\n",
      "Epoch 197, Loss: 0.4740114212036133, Val Loss: 0.5676694512367249\n",
      "end of epoch.\n",
      "start of epoch 198\n",
      "Training loss (for one batch) at step 0: 0.44327405095100403\n",
      "Epoch 198, Loss: 0.44327405095100403, Val Loss: 0.47014120221138\n",
      "end of epoch.\n",
      "start of epoch 199\n",
      "Training loss (for one batch) at step 0: 0.504882276058197\n",
      "Epoch 199, Loss: 0.504882276058197, Val Loss: 0.44429492950439453\n",
      "end of epoch.\n",
      "start of epoch 200\n",
      "Training loss (for one batch) at step 0: 0.4452650249004364\n",
      "Epoch 200, Loss: 0.4452650249004364, Val Loss: 0.5780103206634521\n",
      "end of epoch.\n",
      "Checkpoint directory :  checkpoints/CNNgeo/200507_regressor_filter_size_up\n",
      "Tensorboard log directory :  logs/CNNgeo/200507_regressor_filter_size_up\n"
     ]
    }
   ],
   "source": [
    "model = CNNgeo_debug.train(config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"cnn_geo\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "feature__extractor (Feature_ multiple                  113600    \n",
      "_________________________________________________________________\n",
      "correlation_network (Correla multiple                  0         \n",
      "_________________________________________________________________\n",
      "spatial_transformer_regresso multiple                  875250    \n",
      "=================================================================\n",
      "Total params: 988,850\n",
      "Trainable params: 988,146\n",
      "Non-trainable params: 704\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Debug"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train dataset amount : 1\n"
     ]
    }
   ],
   "source": [
    "datasets = load_data(['train'], config)\n",
    "ds = datasets['train'].batch(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "for image_A, image_B, parameters in ds.take(1):\n",
    "    image_A = image_A.numpy()\n",
    "    image_B = image_B.numpy()\n",
    "    parameters = parameters.numpy()\n",
    "#image_B_hat = np.ones([1, 64, 64, 3])\n",
    "pred, score = model(image_A, image_B)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "parameter shape (1, 9, 2)\n",
      "score shape (1, 16, 16, 16, 16)\n",
      "(1, 64, 64, 3)\n"
     ]
    }
   ],
   "source": [
    "print(\"parameter shape\", pred.shape)\n",
    "print(\"score shape\", score.shape)\n",
    "print(image_A.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.1. 입력 영상에 따른 모델 추정 확인"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### case 1) 임의의 기하관계를 갖는 영상 쌍 (image A, image B)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "compare gt : [[[ 0.09754401 -0.13372193]\n",
      "  [-0.19056873 -0.11294842]\n",
      "  [ 0.01910443 -0.03873439]\n",
      "  [ 0.19635105  0.03928862]\n",
      "  [ 0.16262393 -0.14805971]\n",
      "  [ 0.15199251 -0.03708296]\n",
      "  [ 0.00964065  0.08787113]\n",
      "  [ 0.1878798  -0.05855036]\n",
      "  [ 0.05249725 -0.13828455]]] and \n",
      " pred : [[[-2.8081583e-03  3.1856457e-03]\n",
      "  [-2.1162543e-03 -4.5380862e-03]\n",
      "  [-2.0272008e-03  3.7736213e-04]\n",
      "  [-5.3545679e-03  4.4085295e-03]\n",
      "  [-2.4636951e-03 -3.3418805e-04]\n",
      "  [-2.1106810e-03  1.4780858e-04]\n",
      "  [ 6.9935486e-05  4.3442319e-03]\n",
      "  [-6.8207161e-04  1.9229407e-03]\n",
      "  [-5.8458420e-05  5.9187640e-03]]]\n",
      "loss : [0.13200387]\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 3 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "for image_A, image_B, parameters in ds.take(1):\n",
    "    image_A = image_A.numpy()\n",
    "    image_B = image_B.numpy()\n",
    "    parameters = parameters.numpy()\n",
    "pred, score = model(image_A, image_B)\n",
    "\n",
    "print(\"compare gt : {} and \\n pred : {}\".format(parameters, pred))\n",
    "loss = tf.reduce_sum(tf.keras.losses.MSE(pred, parameters), axis=1)\n",
    "print(\"loss : {}\".format(loss))\n",
    "\n",
    "pred = pred.numpy()\n",
    "image_C = list(map(lambda x : image.synthesize_image(x[0], x[1], (64, 64), bbox=None, pad_ratio=None),\n",
    "                   zip(image_A.copy(), pred.copy())))    \n",
    "image_C = np.array(image_C)\n",
    "visualize.show_TPS_image([image_A, image_B, image_C], [np.ones_like(parameters), parameters, pred])    \n",
    "\n",
    "pred1 = pred.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### case 2) 임의의 다른 기하관계를 갖는 영상 쌍 (image A, image B)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "compare gt : [[[ 0.18370004 -0.01576309]\n",
      "  [-0.16862397 -0.16131316]\n",
      "  [-0.04334063 -0.17331944]\n",
      "  [ 0.00308113 -0.09640288]\n",
      "  [ 0.18076883 -0.16944905]\n",
      "  [ 0.06326161 -0.14166208]\n",
      "  [ 0.13526407  0.10226946]\n",
      "  [-0.12716489 -0.01316743]\n",
      "  [-0.01787152 -0.19832592]]] and \n",
      " pred : [[[-2.8081583e-03  3.1856457e-03]\n",
      "  [-2.1162543e-03 -4.5380862e-03]\n",
      "  [-2.0272008e-03  3.7736213e-04]\n",
      "  [-5.3545679e-03  4.4085295e-03]\n",
      "  [-2.4636951e-03 -3.3418805e-04]\n",
      "  [-2.1106810e-03  1.4780858e-04]\n",
      "  [ 6.9935486e-05  4.3442319e-03]\n",
      "  [-6.8207161e-04  1.9229407e-03]\n",
      "  [-5.8458420e-05  5.9187640e-03]]]\n",
      "loss : [0.15112114]\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 3 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "for image_A, image_B, parameters in ds.take(1):\n",
    "    image_A = image_A.numpy()\n",
    "    image_B = image_B.numpy()\n",
    "    parameters = parameters.numpy()\n",
    "pred, score = model(image_A, image_B)\n",
    "\n",
    "print(\"compare gt : {} and \\n pred : {}\".format(parameters, pred))\n",
    "loss = tf.reduce_sum(tf.keras.losses.MSE(pred, parameters), axis=1)\n",
    "print(\"loss : {}\".format(loss))\n",
    "\n",
    "pred = pred.numpy()\n",
    "image_C = list(map(lambda x : image.synthesize_image(x[0], x[1], (64, 64), bbox=None, pad_ratio=None),\n",
    "                   zip(image_A.copy(), pred.copy())))    \n",
    "image_C = np.array(image_C)\n",
    "visualize.show_TPS_image([image_A, image_B, image_C], [np.ones_like(parameters), parameters, pred])    \n",
    "\n",
    "pred2 = pred.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### case 3) Image A와 연관 없는 image B(백색 사진)의 영상 쌍 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Layer feature__extractor is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "compare gt : [[[ 0.18370004 -0.01576309]\n",
      "  [-0.16862397 -0.16131316]\n",
      "  [-0.04334063 -0.17331944]\n",
      "  [ 0.00308113 -0.09640288]\n",
      "  [ 0.18076883 -0.16944905]\n",
      "  [ 0.06326161 -0.14166208]\n",
      "  [ 0.13526407  0.10226946]\n",
      "  [-0.12716489 -0.01316743]\n",
      "  [-0.01787152 -0.19832592]]] and \n",
      " pred : [[[-2.8081583e-03  3.1856457e-03]\n",
      "  [-2.1162543e-03 -4.5380862e-03]\n",
      "  [-2.0272008e-03  3.7736213e-04]\n",
      "  [-5.3545679e-03  4.4085295e-03]\n",
      "  [-2.4636951e-03 -3.3418805e-04]\n",
      "  [-2.1106810e-03  1.4780858e-04]\n",
      "  [ 6.9935486e-05  4.3442319e-03]\n",
      "  [-6.8207161e-04  1.9229407e-03]\n",
      "  [-5.8458420e-05  5.9187640e-03]]]\n",
      "loss : [0.15112114]\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 3 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "image_B = np.ones([1, 64, 64, 3])\n",
    "pred, score = model(image_A, image_B)\n",
    "\n",
    "print(\"compare gt : {} and \\n pred : {}\".format(parameters, pred))\n",
    "loss = tf.reduce_sum(tf.keras.losses.MSE(pred, parameters), axis=1)\n",
    "print(\"loss : {}\".format(loss))\n",
    "\n",
    "pred = pred.numpy()\n",
    "image_C = list(map(lambda x : image.synthesize_image(x[0], x[1], (64, 64), bbox=None, pad_ratio=None),\n",
    "                   zip(image_A.copy(), pred.copy())))    \n",
    "image_C = np.array(image_C)\n",
    "visualize.show_TPS_image([image_A, image_B, image_C], [np.ones_like(parameters), parameters, pred])    \n",
    "\n",
    "pred3 = pred.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[-2.8081583e-03  3.1856457e-03]\n",
      "  [-2.1162543e-03 -4.5380862e-03]\n",
      "  [-2.0272008e-03  3.7736213e-04]\n",
      "  [-5.3545679e-03  4.4085295e-03]\n",
      "  [-2.4636951e-03 -3.3418805e-04]\n",
      "  [-2.1106810e-03  1.4780858e-04]\n",
      "  [ 6.9935486e-05  4.3442319e-03]\n",
      "  [-6.8207161e-04  1.9229407e-03]\n",
      "  [-5.8458420e-05  5.9187640e-03]]] \n",
      " [[[-2.8081583e-03  3.1856457e-03]\n",
      "  [-2.1162543e-03 -4.5380862e-03]\n",
      "  [-2.0272008e-03  3.7736213e-04]\n",
      "  [-5.3545679e-03  4.4085295e-03]\n",
      "  [-2.4636951e-03 -3.3418805e-04]\n",
      "  [-2.1106810e-03  1.4780858e-04]\n",
      "  [ 6.9935486e-05  4.3442319e-03]\n",
      "  [-6.8207161e-04  1.9229407e-03]\n",
      "  [-5.8458420e-05  5.9187640e-03]]] \n",
      " [[[-2.8081583e-03  3.1856457e-03]\n",
      "  [-2.1162543e-03 -4.5380862e-03]\n",
      "  [-2.0272008e-03  3.7736213e-04]\n",
      "  [-5.3545679e-03  4.4085295e-03]\n",
      "  [-2.4636951e-03 -3.3418805e-04]\n",
      "  [-2.1106810e-03  1.4780858e-04]\n",
      "  [ 6.9935486e-05  4.3442319e-03]\n",
      "  [-6.8207161e-04  1.9229407e-03]\n",
      "  [-5.8458420e-05  5.9187640e-03]]]\n"
     ]
    }
   ],
   "source": [
    "print(pred1, \"\\n\", pred2, \"\\n\", pred3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "case 1)와 case 2)는 동일한 영상을 다른 기하관계를 사용하여 두 개의 영상쌍(image pair)을 만든 경우를 말한다. 모델이 정상적이라면 각 영상쌍의 기하관계를 추정할 수 있을 것이다. 그러나 두 영상쌍이 다른 기하관계를 갖음에도 동일한 모션파라미터를 추정하였다. case 3)에서는 전혀 연관 없는 영상을 image B로 사용하였다. image B는 어떤 특징 정보도 없는 백색 사진임에도 불구하고 모델은 case 1)과 case 2)에서와 같은 모션파라미터를 추정하였다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"cnn_geo\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "feature__extractor (Feature_ multiple                  113600    \n",
      "_________________________________________________________________\n",
      "correlation_network (Correla multiple                  0         \n",
      "_________________________________________________________________\n",
      "spatial_transformer_regresso multiple                  875250    \n",
      "=================================================================\n",
      "Total params: 988,850\n",
      "Trainable params: 988,146\n",
      "Non-trainable params: 704\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.2 Correlation 분포에 따른 Regressor 예측"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3.1의 case 1, 2, 3에서 Regressor은 같은 모션파라미터를 예측했다. 명확한 이유를 파악하기 위해 입력 correlation(matching scores)를 제어하며 spatial parameter regressor의 출력을 분석했다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Layer spatial_transformer_regressor is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "tf.Tensor(\n",
      "[[-2.8081583e-03  3.1856457e-03 -2.1162543e-03 -4.5380862e-03\n",
      "  -2.0272008e-03  3.7736213e-04 -5.3545679e-03  4.4085295e-03\n",
      "  -2.4636951e-03 -3.3418805e-04 -2.1106810e-03  1.4780858e-04\n",
      "   6.9935486e-05  4.3442319e-03 -6.8207161e-04  1.9229407e-03\n",
      "  -5.8458420e-05  5.9187640e-03]], shape=(1, 18), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "x = np.zeros([1, 16, 16, 16, 16]) # all correlations are zero\n",
    "y = model.layers[2](x)\n",
    "print(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(\n",
      "[[-2.8081583e-03  3.1856457e-03 -2.1162543e-03 -4.5380862e-03\n",
      "  -2.0272008e-03  3.7736213e-04 -5.3545679e-03  4.4085295e-03\n",
      "  -2.4636951e-03 -3.3418805e-04 -2.1106810e-03  1.4780858e-04\n",
      "   6.9935486e-05  4.3442319e-03 -6.8207161e-04  1.9229407e-03\n",
      "  -5.8458420e-05  5.9187640e-03]], shape=(1, 18), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "x = np.ones([1, 16, 16, 16, 16]) # all correlations are one\n",
    "y = model.layers[2](x)\n",
    "print(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(\n",
      "[[-2.8081583e-03  3.1856457e-03 -2.1162543e-03 -4.5380862e-03\n",
      "  -2.0272008e-03  3.7736213e-04 -5.3545679e-03  4.4085295e-03\n",
      "  -2.4636951e-03 -3.3418805e-04 -2.1106810e-03  1.4780858e-04\n",
      "   6.9935486e-05  4.3442319e-03 -6.8207161e-04  1.9229407e-03\n",
      "  -5.8458420e-05  5.9187640e-03]], shape=(1, 18), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "x = np.random.normal(loc=0.5, scale=0.0, size=[1, 16, 16, 16, 16])\n",
    "y = model.layers[2](x)\n",
    "print(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(\n",
      "[[ 0.00394962 -0.01790469  0.05764657  0.01544581  0.00590207 -0.04274273\n",
      "  -0.01870706 -0.02243117 -0.08493273  0.00087138  0.04015159 -0.0439481\n",
      "  -0.04103261 -0.01469471 -0.01763722 -0.06848349 -0.01065879 -0.02943587]], shape=(1, 18), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "x = np.random.normal(loc=0.5, scale=0.3, size=[1, 16, 16, 16, 16])\n",
    "y = model.layers[2](x)\n",
    "print(y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "위 실험의 결과를 토대로 확인할 수 있는 것은 regressor의 출력은 입력 correlation의 크기가 아닌 편차에 따라 달라진다는 것이다. correlation의 분포의 표준편차를 변화시키며 출력의 변화 정도를 추정해주었다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.         0.02040816 0.04081633 0.06122449 0.08163265 0.10204082\n",
      " 0.12244898 0.14285714 0.16326531 0.18367347 0.20408163 0.2244898\n",
      " 0.24489796 0.26530612 0.28571429 0.30612245 0.32653061 0.34693878\n",
      " 0.36734694 0.3877551  0.40816327 0.42857143 0.44897959 0.46938776\n",
      " 0.48979592 0.51020408 0.53061224 0.55102041 0.57142857 0.59183673\n",
      " 0.6122449  0.63265306 0.65306122 0.67346939 0.69387755 0.71428571\n",
      " 0.73469388 0.75510204 0.7755102  0.79591837 0.81632653 0.83673469\n",
      " 0.85714286 0.87755102 0.89795918 0.91836735 0.93877551 0.95918367\n",
      " 0.97959184 1.        ]\n"
     ]
    }
   ],
   "source": [
    "_range = np.linspace(0, 1.0, 50)\n",
    "print(_range)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "variations_via_std = []\n",
    "variations_via_mean = []\n",
    "for std in _range:\n",
    "    x = np.random.normal(loc=0.5, scale=std, size=[1, 16, 16, 16, 16])\n",
    "    _y = model.layers[2](x)\n",
    "    variation = np.square(np.sum(np.power((y - _y), 2)))\n",
    "    variations_via_std.append(variation)\n",
    "for mean in _range:\n",
    "    x = np.random.normal(loc=mean, scale=0.1, size=[1, 16, 16, 16, 16])\n",
    "    _y = model.layers[2](x)\n",
    "    variation = np.square(np.sum(np.power((y - _y), 2)))\n",
    "    variations_via_mean.append(variation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.ylabel(\"variation of motion parameters\")\n",
    "plt.xlabel(\"std-dev or mean\")\n",
    "plt.plot(_range, variations_via_std, label='variation_via_std')\n",
    "plt.plot(_range, variations_via_mean, label='variation_via_mean')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. VGG16을 통한 correlations\n",
    "2. 시각화 방식 개선\n",
    "3. tentative penalty"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## b. 특징추출기의 정상 동작 검증"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 동일 영상에 대한 correlation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(16, 16, 16, 16) (9, 2) (64, 64, 3)\n"
     ]
    }
   ],
   "source": [
    "for image_A, image_B, parameters in ds.take(1):\n",
    "    image_A = image_A.numpy()\n",
    "    image_B = image_B.numpy()\n",
    "    parameters = parameters.numpy()\n",
    "pred, score = model(image_A, image_A)\n",
    "\n",
    "score = score.numpy()[0]\n",
    "parameters = parameters[0]\n",
    "image_A = image_A[0]\n",
    "image_B = image_B[0]\n",
    "\n",
    "print(score.shape, parameters.shape, image_A.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_matching_grid_from_B(parameters, center_point):\n",
    "    src_points = np.array([[0.0, 0.0], [0.5, 0.0], [1.0, 0.0],\n",
    "                                   [0.0, 0.5], [0.5, 0.5], [1.0, 0.5],\n",
    "                                   [0.0, 1.0], [0.5, 1.0], [1.0, 1.0]])\n",
    "\n",
    "    dst_points = src_points +parameters\n",
    "\n",
    "    theta = tps.tps_theta_from_points(src_points, dst_points, reduced=True)\n",
    "    dshape = (64, 64)\n",
    "    grid = tps.tps_grid(theta, dst_points, dshape)\n",
    "    mapx, mapy = tps.tps_grid_to_remap(grid, (64, 64))\n",
    "    points = np.concatenate([mapy[:,:,np.newaxis], mapx[:,:,np.newaxis]], axis=2)\n",
    "    #print(\"points :\", points)\n",
    "    center_point = np.array(center_point)\n",
    "    #print(\"grid center : \", center_point)\n",
    "    center_point = center_point[np.newaxis, np.newaxis, :]\n",
    "    distance = np.sum(np.power((points - center_point), 2), axis=2)\n",
    "    #print(\"distance : \", distance)\n",
    "    ri, ci = distance.argmin()//distance.shape[1], distance.argmin()%distance.shape[1]\n",
    "    return (ri, ci)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def score_test(grid_coord, score, parameters, images, grid_shape=(16,16)):\n",
    "    image_A, image_B = images\n",
    "    score = score[grid_coord[0], grid_coord[1]]\n",
    "    H, W, C = image_A.shape\n",
    "    grid_size = H/grid_shape[0], W/grid_shape[1]\n",
    "\n",
    "    start_pix_h = int(grid_size[0]*grid_coord[0])\n",
    "    end_pix_h = int(grid_size[0]*(1+grid_coord[0]))\n",
    "    start_pix_w = int(grid_size[1]*grid_coord[1])\n",
    "    end_pix_w = int(grid_size[1]*(1+grid_coord[1]))\n",
    "    \n",
    "    drawn_grid_image_A = image_A.copy()\n",
    "    drawn_grid_image_A[start_pix_h:end_pix_h, start_pix_w:end_pix_w] = (0,0,0)   \n",
    "    \n",
    "    expected_drawn_grid_image_B = image_B.copy()\n",
    "    grid_center_A = (int(start_pix_h+grid_size[0]/2), int(start_pix_w+grid_size[1]/2))\n",
    "    grid_center_B = get_matching_grid_from_B(parameters, grid_center_A)\n",
    "    start_pix_h = int(grid_center_B[0] - grid_size[0]/2)\n",
    "    start_pix_w = int(grid_center_B[1] - grid_size[1]/2)\n",
    "    end_pix_h = int(grid_center_B[0] + grid_size[0]/2)\n",
    "    end_pix_w = int(grid_center_B[1] + grid_size[1]/2)\n",
    "    expected_drawn_grid_image_B[start_pix_h:end_pix_h, start_pix_w:end_pix_w] = (0,0,0)\n",
    "    \n",
    "    drawn_grid_image_B = image_B.copy()\n",
    "    max_correlation_grid_index = score.argmax()//score.shape[1], score.argmax()%score.shape[1]\n",
    "    start_pix_h = int(grid_size[0]*max_correlation_grid_index[0])\n",
    "    end_pix_h = int(grid_size[0]*(1+max_correlation_grid_index[0]))\n",
    "    start_pix_w = int(grid_size[1]*max_correlation_grid_index[1])\n",
    "    end_pix_w = int(grid_size[1]*(1+max_correlation_grid_index[1]))\n",
    "\n",
    "    drawn_grid_image_B[start_pix_h:end_pix_h, start_pix_w:end_pix_w] = (0,0,0)\n",
    "    \n",
    "    print(\"top 10 correlation values in descending : \", np.sort(score.flatten())[::-1][:10])\n",
    "    \n",
    "    return drawn_grid_image_A, expected_drawn_grid_image_B, drawn_grid_image_B"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "drawn_image_A, expected_drawn_grid_image_B, drawn_grid_image_B = score_test(grid_coord=(5,10), \n",
    "                                                                            score=score, \n",
    "                                                                            parameters=np.zeros([9,2]), \n",
    "                                                                            images=(image_A, image_A))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure()\n",
    "\n",
    "ax1 = fig.add_subplot(131)\n",
    "ax2 = fig.add_subplot(132)\n",
    "ax3 = fig.add_subplot(133)\n",
    "\n",
    "ax1.imshow(drawn_image_A)\n",
    "ax2.imshow(expected_drawn_grid_image_B)\n",
    "ax3.imshow(drawn_grid_image_B)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "drawn_image_A.shape\n",
    "expected_drawn_grid_image_B.shape\n",
    "drawn_grid_image_B.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### b.1 ) 동일한 사진의 경우"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(16):\n",
    "    drawn_image_A, expected_drawn_grid_image_B, drawn_grid_image_B = score_test(grid_coord=(i,i), \n",
    "                                                                                score=score, \n",
    "                                                                                parameters=np.zeros([9,2]), \n",
    "                                                                                images=(image_A, image_A))   \n",
    "    fig = plt.figure()\n",
    "\n",
    "    ax1 = fig.add_subplot(131)\n",
    "    ax2 = fig.add_subplot(132)\n",
    "    ax3 = fig.add_subplot(133)\n",
    "\n",
    "    ax1.imshow(drawn_image_A)\n",
    "    ax2.imshow(expected_drawn_grid_image_B)\n",
    "    ax3.imshow(drawn_grid_image_B)\n",
    "\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### b.2 ) 다른 사진의 경우"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for image_A, image_B, parameters in ds.take(1):\n",
    "    image_A = image_A.numpy()\n",
    "    image_B = image_B.numpy()\n",
    "    parameters = parameters.numpy()\n",
    "pred, score = model(image_A, image_A)\n",
    "\n",
    "score = score.numpy()[0]\n",
    "parameters = parameters[0]\n",
    "image_A = image_A[0]\n",
    "image_B = image_B[0]\n",
    "\n",
    "print(score.shape, parameters.shape, image_A.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(16):\n",
    "    drawn_image_A, expected_drawn_grid_image_B, drawn_grid_image_B = score_test(grid_coord=(i,i), \n",
    "                                                                                score=score, \n",
    "                                                                                parameters=parameters, \n",
    "                                                                                images=(image_A, image_B))   \n",
    "    fig = plt.figure()\n",
    "\n",
    "    ax1 = fig.add_subplot(131)\n",
    "    ax2 = fig.add_subplot(132)\n",
    "    ax3 = fig.add_subplot(133)\n",
    "\n",
    "    ax1.imshow(drawn_image_A)\n",
    "    ax2.imshow(expected_drawn_grid_image_B)\n",
    "    ax3.imshow(drawn_grid_image_B)\n",
    "\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from models.cnn_geo import CNN_geo\n",
    "from data_loader import load_data\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = CNN_geo(config['backbone'])\n",
    "ckpt_dir = os.path.join(\n",
    "        'checkpoints', config['model_name'], config['exp_desc'])\n",
    "ckpt = os.path.join(ckpt_dir, \"{}-{}.h5\".format(config['model_name'], str(config['train']['epochs'])))\n",
    "model.load(ckpt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.layers[2](np.ones([1, 16,16,16,16]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datasets = load_data(['train'], config)\n",
    "ds = datasets['train'].batch(1)\n",
    "for image_A, image_B, parameters in ds.take(1):\n",
    "    image_A = image_A.numpy()\n",
    "    image_B = image_B.numpy()\n",
    "    parameters = parameters.numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_A.shape, image_B.shape\n",
    "\n",
    "x = model.layers[0](image_A)\n",
    "y = model.layers[0](image_B)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(image_A[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(image_B[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "score = model.layers[1](x, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "float_formatter = \"{:.3f}\".format\n",
    "np.set_printoptions(formatter={'float_kind':float_formatter})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(np.max(score[0, 0,0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(score[0,0,0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.layers[2](score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vgg = tf.keras.applications.VGG16(weights='imagenet', input_shape=(64, 64, 3), include_top=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.keras.Model(inputs=vgg.layers[0].input, outputs=vgg.layers[9].output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

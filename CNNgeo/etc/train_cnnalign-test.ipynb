{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from geo_transform.tf_tps import ThinPlateSpline as tps\n",
    "\n",
    "import cv2\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.applications.vgg16 import preprocess_input\n",
    "from functools import partial\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 Physical GPUs, 1 Logical GPUs\n"
     ]
    }
   ],
   "source": [
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"1\"\n",
    "from utils import tf_session\n",
    "tf_session.setup_gpus(True, 0.95)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1.Data load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from data_loader.dev_dataset import tf_image_process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "_datapath = \"sample_dataset\"\n",
    "filelist = os.listdir(_datapath)\n",
    "input_size = (200, 200)\n",
    "\n",
    "images = []\n",
    "\n",
    "for f in filelist:\n",
    "    _path = os.path.join(_datapath, f)\n",
    "    img = cv2.imread(_path)[:,:,::-1]\n",
    "    img = cv2.resize(img, input_size, interpolation=cv2.INTER_AREA)\n",
    "    images.append(img)\n",
    "\n",
    "images = np.array(images, dtype=np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "tps_random_rate = 0.4\n",
    "output_size = (200, 200)\n",
    "map_func = partial(tf_image_process, tps_random_rate=tps_random_rate,\n",
    "                      output_size=output_size)\n",
    "ds = tf.data.Dataset.from_tensor_slices(images)\n",
    "ds = ds.map(map_func, num_parallel_calls=tf.data.experimental.AUTOTUNE)\n",
    "ds = ds.batch(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10, 200, 200, 3) (10, 200, 200, 3)\n",
      "(10, 9, 2)\n"
     ]
    }
   ],
   "source": [
    "for A, B, p in ds.take(1):\n",
    "    print(A.shape, B.shape)\n",
    "    print(p.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(images[1]/255)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(A[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(B[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Model definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from models.cnngeo import CNN_geotransform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# (a) feature extraction\n",
    "vgg16 = tf.keras.applications.VGG16(weights='imagenet', input_shape=(input_size[0], input_size[1], 3), \n",
    "                                    include_top=False)\n",
    "output_layer = vgg16.get_layer(\"block4_conv3\")\n",
    "output_layer.activation = None\n",
    "feature_extractor = tf.keras.Model(inputs=vgg16.input, outputs=output_layer.output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "cnngeo = CNN_geotransform(feature_extractor, 18)\n",
    "geo_parameters, correlations = cnngeo(A, B)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "cnngeo.load_weights(\"cnngeo.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cnngeo.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "def generate_inlier_mask(moving_vectors, map_size, thresh=30):\n",
    "    batch_size = len(geo_parameters)\n",
    "    height, width = map_size\n",
    "    x_t = tf.tile(tf.reshape(tf.linspace(0.0, width-1.0, width), [1, width]), [height, 1])\n",
    "    y_t = tf.tile(tf.reshape(tf.linspace(0.0, height-1.0, height), [height, 1]), [1, width])    \n",
    "    x_t = tf.tile(x_t[tf.newaxis,::], [batch_size, 1, 1]) # [BN, H, W]\n",
    "    y_t = tf.tile(y_t[tf.newaxis,::], [batch_size, 1, 1]) # [BN, H, W]\n",
    "    \n",
    "    control_points = tf.constant([[-1.0, -1.0], [0.0, -1.0], [1.0, -1.0],\n",
    "                                   [-1.0, 0.0], [0.0, 0.0], [1.0, 0.0],\n",
    "                                   [-1.0, 1.0], [0.0, 1.0], [1.0, 1.0]], dtype=tf.float32)    \n",
    "    control_points = tf.tile(control_points[tf.newaxis,::], [batch_size, 1, 1]) # [BN, 9, 2]\n",
    "    x_p, y_p = tps(control_points, -moving_vectors, (height, width))\n",
    "    \n",
    "    x_t, y_t = x_t[:,:,:,tf.newaxis,tf.newaxis], y_t[:,:,:,tf.newaxis,tf.newaxis] #[BN,H,W,1,1]\n",
    "    x_p, y_p = x_p[:,tf.newaxis,tf.newaxis,:,:], y_p[:,tf.newaxis,tf.newaxis,:,:] #[BN,1,1,H,W]\n",
    "    # L2 distance of grids of featureA and grids of featureB, transformed by the estimated geometric transformation.\n",
    "    l2_dist = tf.sqrt(tf.pow(x_t - x_p, 2) + tf.pow(y_t - y_p, 2)) \n",
    "    #inlier_mask = l2_dist\n",
    "    inlier_mask = tf.cond(l2_dist < height/thresh, 1, 0)\n",
    "    return inlier_mask\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/tensorflow_addons/utils/resource_loader.py:103: UserWarning: You are currently using TensorFlow 2.3.0-rc2 and trying to load a custom op (custom_ops/image/_resampler_ops.so).\n",
      "TensorFlow Addons has compiled its custom ops against TensorFlow 2.2.0, and there are no compatibility guarantees between the two versions. \n",
      "This means that you might get segfaults when loading the custom op, or other kind of low-level errors.\n",
      " If you do, do not file an issue on Github. This is a known limitation.\n",
      "\n",
      "It might help you to fallback to pure Python ops with TF_ADDONS_PY_OPS . To do that, see https://github.com/tensorflow/addons#gpucpu-custom-ops \n",
      "\n",
      "You can also change the TensorFlow version installed on your system. You would need a TensorFlow version equal to or above 2.2.0 and strictly below 2.3.0.\n",
      " Note that nightly versions of TensorFlow, as well as non-pip TensorFlow like `conda install tensorflow` or compiled from source are not supported.\n",
      "\n",
      "The last solution is to find the TensorFlow Addons version that has custom ops compatible with the TensorFlow installed on your system. To do that, refer to the readme: https://github.com/tensorflow/addons\n",
      "  UserWarning,\n"
     ]
    }
   ],
   "source": [
    "import tensorflow_addons as tfa\n",
    "\n",
    "moving_vectors = tf.constant([[0.3, 0.0], [0.3, 0.0], [0.3, 0.0],\n",
    "                                   [0.3, 0.0], [0.3, 0.3], [0.3, 0.0],\n",
    "                                   [0.3, 0.0], [0.3, 0.0], [0.3, 0.0]], dtype=tf.float32) \n",
    "geo_parameters = moving_vectors[tf.newaxis,::]\n",
    "batch_size=len(geo_parameters)\n",
    "\n",
    "#fake image\n",
    "x = np.zeros([3,15,15,1], np.float32)\n",
    "x[0,0,0] = 1\n",
    "x[1,7,7] = 1\n",
    "x[2,14,14] = 1\n",
    "\n",
    "control_points = tf.constant([[-1.0, -1.0], [0.0, -1.0], [1.0, -1.0],\n",
    "                                   [-1.0, 0.0], [0.0, 0.0], [1.0, 0.0],\n",
    "                                   [-1.0, 1.0], [0.0, 1.0], [1.0, 1.0]], dtype=tf.float32) \n",
    "control_points = tf.tile(control_points[tf.newaxis,::], [3, 1, 1]) # [BN, 9, 2]\n",
    "geo_parameters = tf.tile(geo_parameters, [3, 1, 1]) # [BN, 9, 2]\n",
    "x_s, y_s = tps(control_points, -geo_parameters, (15,15))\n",
    "remaps = tf.stack([x_s, y_s], axis=-1)\n",
    "sampled_image = tfa.image.resampler(x, remaps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "figure = plt.figure()\n",
    "figure.add_subplot(131).imshow(x[0,:,:,0])\n",
    "figure.add_subplot(132).imshow(x[1,:,:,0])\n",
    "figure.add_subplot(133).imshow(x[2,:,:,0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "figure = plt.figure()\n",
    "figure.add_subplot(131).imshow(sampled_image[0,:,:,0])\n",
    "figure.add_subplot(132).imshow(sampled_image[1,:,:,0])\n",
    "figure.add_subplot(133).imshow(sampled_image[2,:,:,0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "figure = plt.figure()\n",
    "figure.add_subplot(131).imshow(sampled_image[0,:,:,0])\n",
    "figure.add_subplot(132).imshow(sampled_image[1,:,:,0])\n",
    "figure.add_subplot(133).imshow(sampled_image[2,:,:,0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "figure = plt.figure()\n",
    "figure.add_subplot(131).imshow(sampled_image[0,:,:,0])\n",
    "figure.add_subplot(132).imshow(sampled_image[1,:,:,0])\n",
    "figure.add_subplot(133).imshow(sampled_image[2,:,:,0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "moving_vectors = tf.constant([[0.3, 0.3], [0.3, 0.0], [0.3, 0.0],\n",
    "                                   [0.3, 0.0], [0.0, 0.3], [0.3, 0.0],\n",
    "                                   [0.3, 0.0], [0.3, 0.0], [-0.3, 0.0]], dtype=tf.float32) \n",
    "geo_parameters = moving_vectors[tf.newaxis,::]\n",
    "batch_size = 1\n",
    "\n",
    "height, width = 15, 15\n",
    "identity_mask = np.zeros((height*width*height*width))\n",
    "idx_list = list(range(0, height*width*height*width, height*width+1))\n",
    "identity_mask[idx_list] = 1\n",
    "identity_mask = np.reshape(identity_mask, (1, height,width,height,width))\n",
    "    \n",
    "identity_mask = tf.constant(identity_mask, tf.float32)\n",
    "identity_mask = tf.tile(identity_mask, [batch_size,1,1,1,1])\n",
    "\n",
    "#calculate estimated coordinates of source grids on target feature grids\n",
    "control_points = tf.constant([[-1.0, -1.0], [0.0, -1.0], [1.0, -1.0],\n",
    "                                   [-1.0, 0.0], [0.0, 0.0], [1.0, 0.0],\n",
    "                                   [-1.0, 1.0], [0.0, 1.0], [1.0, 1.0]], dtype=tf.float32) \n",
    "\n",
    "control_points = tf.tile(control_points[tf.newaxis,::], [batch_size*height*width, 1, 1])\n",
    "geo_parameters = tf.tile(geo_parameters, [batch_size*height*width, 1, 1])\n",
    "\n",
    "x_s, y_s = tps(control_points, -geo_parameters, (height,width))\n",
    "remaps = tf.stack([x_s, y_s], axis=-1)\n",
    "\n",
    "reshaped_identity_mask = tf.reshape(identity_mask, [batch_size*height*width, height, width, 1])\n",
    "sampled_image = tfa.image.resampler(reshaped_identity_mask, remaps)\n",
    "sampled_image = tf.reshape(sampled_image, [batch_size, height,width,height,width])\n",
    "\n",
    "figure = plt.figure()\n",
    "figure.add_subplot(231).imshow(identity_mask[0,0,0])\n",
    "figure.add_subplot(232).imshow(identity_mask[0,7,7])\n",
    "figure.add_subplot(233).imshow(identity_mask[0,14,14])\n",
    "\n",
    "figure.add_subplot(234).imshow(sampled_image[0,0,0])\n",
    "figure.add_subplot(235).imshow(sampled_image[0,7,7])\n",
    "figure.add_subplot(236).imshow(sampled_image[0,14,14])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "geo_parameters, correlations = cnngeo(A,B)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "geo_parameters.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "geo_parameters = tf.concat([geo_parameters, moving_vectors[tf.newaxis,::]], axis=0)\n",
    "print(geo_parameters.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 11\n",
    "\n",
    "height, width = 15, 15\n",
    "identity_mask = np.zeros((height*width*height*width))\n",
    "idx_list = list(range(0, height*width*height*width, height*width+1))\n",
    "identity_mask[idx_list] = 1\n",
    "identity_mask = np.reshape(identity_mask, (1, height,width,height,width))\n",
    "    \n",
    "identity_mask = tf.constant(identity_mask, tf.float32)\n",
    "identity_mask = tf.tile(identity_mask, [batch_size,1,1,1,1])\n",
    "\n",
    "#calculate estimated coordinates of source grids on target feature grids\n",
    "control_points = tf.constant([[-1.0, -1.0], [0.0, -1.0], [1.0, -1.0],\n",
    "                                   [-1.0, 0.0], [0.0, 0.0], [1.0, 0.0],\n",
    "                                   [-1.0, 1.0], [0.0, 1.0], [1.0, 1.0]], dtype=tf.float32) \n",
    "\n",
    "control_points = tf.tile(control_points[tf.newaxis,::], [batch_size*height*width, 1, 1])\n",
    "geo_parameters = geo_parameters[tf.newaxis,::]\n",
    "geo_parameters = tf.tile(geo_parameters, [height*width, 1, 1, 1])\n",
    "geo_parameters = tf.reshape(geo_parameters, [batch_size*height*width,9, 2])\n",
    "\n",
    "x_s, y_s = tps(control_points, -geo_parameters, (height,width))\n",
    "remaps = tf.stack([x_s, y_s], axis=-1)\n",
    "\n",
    "reshaped_identity_mask = tf.reshape(identity_mask, [batch_size*height*width, height, width, 1])\n",
    "sampled_image = tfa.image.resampler(reshaped_identity_mask, remaps)\n",
    "sampled_image = tf.reshape(sampled_image, [batch_size, height,width,height,width])\n",
    "\n",
    "figure = plt.figure()\n",
    "figure.add_subplot(231).imshow(identity_mask[10,0,0])\n",
    "figure.add_subplot(232).imshow(identity_mask[10,7,7])\n",
    "figure.add_subplot(233).imshow(identity_mask[10,14,14])\n",
    "\n",
    "figure.add_subplot(234).imshow(sampled_image[10,0,0])\n",
    "figure.add_subplot(235).imshow(sampled_image[10,7,7])\n",
    "figure.add_subplot(236).imshow(sampled_image[10,14,14])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "geo_parameters, correlations = cnngeo(A,B)\n",
    "moving_vectors = tf.constant([[0.0, 0.0], [0.0, 0.0], [0.0, 0.0],\n",
    "                                   [0.0, 0.0], [0.2, 0.2], [0.0, 0.0],\n",
    "                                   [0.0, 0.0], [0.0, 0.0], [-0.3, 0.0]], dtype=tf.float32) \n",
    "\n",
    "geo_parameters = tf.concat([geo_parameters, moving_vectors[tf.newaxis,::]], axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "geo_parameters.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "geo_parameters[10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size=len(geo_parameters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "height, width = 15, 15\n",
    "identity_mask = np.zeros((height*width*height*width))\n",
    "idx_list = list(range(0, height*width*height*width, height*width+1))\n",
    "identity_mask[idx_list] = 1\n",
    "identity_mask = np.reshape(identity_mask, (1, height,width,height,width))\n",
    "    \n",
    "identity_mask = tf.constant(identity_mask, tf.float32)\n",
    "identity_mask = tf.tile(identity_mask, [batch_size,1,1,1,1])\n",
    "\n",
    "#calculate estimated coordinates of source grids on target feature grids\n",
    "control_points = tf.constant([[-1.0, -1.0], [0.0, -1.0], [1.0, -1.0],\n",
    "                                   [-1.0, 0.0], [0.0, 0.0], [1.0, 0.0],\n",
    "                                   [-1.0, 1.0], [0.0, 1.0], [1.0, 1.0]], dtype=tf.float32)  \n",
    "\n",
    "control_points = tf.tile(control_points[tf.newaxis,::], [batch_size, 1, 1]) # [BN, 9, 2]\n",
    "\n",
    "x_s, y_s = tps(control_points, -geo_parameters, (height,width))\n",
    "remaps = tf.stack([x_s, y_s], axis=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "remaps.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_identity_mask = tf.reshape(identity_mask, [batch_size*height*width, height, width, 1])\n",
    "\n",
    "_remaps = tf.tile(remaps[:,tf.newaxis,::], [1,height*width, 1, 1, 1])\n",
    "\n",
    "print(_identity_mask.shape)\n",
    "print(_remaps.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_remaps = tf.reshape(_remaps, [batch_size*height*width,height,width,2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "converted_mask = tfa.image.resampler(_identity_mask, _remaps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inverse_identity_mask = tf.reshape(_identity_mask, [batch_size,height,width,height,width])\n",
    "inverse_converted_mask = tf.reshape(converted_mask, [batch_size, height, width, height, width])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "figure = plt.figure()\n",
    "figure.add_subplot(231).imshow(inverse_identity_mask[10,0,0])\n",
    "figure.add_subplot(232).imshow(inverse_identity_mask[10,7,7])\n",
    "figure.add_subplot(233).imshow(inverse_identity_mask[10,14,14])\n",
    "figure.add_subplot(234).imshow(inverse_converted_mask[10,0,0])\n",
    "figure.add_subplot(235).imshow(inverse_converted_mask[10,7,7])\n",
    "figure.add_subplot(236).imshow(inverse_converted_mask[10,14,14])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "geo_parameters, correlations = cnngeo(A,B)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.ndimage.morphology import binary_dilation, generate_binary_structure\n",
    "\n",
    "def generate_inlier_mask(geo_parameters, map_size, thresh=30):\n",
    "    batch_size=len(geo_parameters)\n",
    "    height, width = map_size\n",
    "    identity_mask = np.zeros((height*width*height*width))\n",
    "    idx_list = list(range(0, height*width*height*width, height*width+1))\n",
    "    identity_mask[idx_list] = 1\n",
    "    identity_mask = np.reshape(identity_mask, (height,width,height,width))\n",
    "    dilation_filter = generate_binary_structure(2, 2)\n",
    "    for h in range(height):\n",
    "        for w in range(width):\n",
    "            identity_mask[h,w] = binary_dilation(identity_mask[h,w], structure=dilation_filter).astype(identity_mask.dtype)\n",
    "    identity_mask = identity_mask[tf.newaxis,::]\n",
    "    identity_mask = np.reshape(identity_mask, (1, height,width,height,width))\n",
    "\n",
    "    identity_mask = tf.constant(identity_mask, tf.float32)\n",
    "    identity_mask = tf.tile(identity_mask, [batch_size,1,1,1,1]) #[BN,H,W,H,W] of identity matrix\n",
    "    '''\n",
    "        We reshape it for convenient parallel processing of remapping.\n",
    "        Each H*W inlier masks are remaped by the same geometric transformation.\n",
    "        Therefore, We calculate BN remaps and repeat H*W of it.\n",
    "    '''\n",
    "    identity_mask = tf.reshape(identity_mask, [batch_size*height*width, height, width, 1]) #[BN*H*W,H,W,1].\n",
    "\n",
    "    #calculate estimated coordinates of source grids on target feature grids\n",
    "    control_points = tf.constant([[-1.0, -1.0], [0.0, -1.0], [1.0, -1.0],\n",
    "                                       [-1.0, 0.0], [0.0, 0.0], [1.0, 0.0],\n",
    "                                       [-1.0, 1.0], [0.0, 1.0], [1.0, 1.0]], dtype=tf.float32)  \n",
    "    control_points = tf.tile(control_points[tf.newaxis,::], [batch_size, 1, 1]) # [BN, 9, 2]\n",
    "    x_s, y_s = tps(control_points, -geo_parameters, (height,width))\n",
    "    #calculate BN remaps\n",
    "    remaps = tf.stack([x_s, y_s], axis=-1) #[BN,H,W,2]\n",
    "    #repeat each remap H*W times. \n",
    "    remaps = tf.tile(remaps[:,tf.newaxis,::], [1,height*width, 1, 1, 1]) #[BN,H*W,H,W,2]\n",
    "    print(remaps.shape)\n",
    "    remaps = tf.reshape(remaps, [batch_size*height*width,height,width,2]) #[BN*H*W,H,W,2]\n",
    "\n",
    "    inlier_masks = tfa.image.resampler(identity_mask, remaps) #inputs <= identity_mask([BN*H*W,H,W,1]) remaps([BN*H*W,H,W,2])\n",
    "    inlier_masks = tf.reshape(inlier_masks, [batch_size, height, width, height, width]) #reshape again. \n",
    "    return inlier_masks #[BN,H,W,H,W]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "moving_vectors = tf.constant([[0.0, 0.0], [0.0, 0.0], [0.0, 0.0],\n",
    "                                   [0.0, 0.0], [0.0, 0.0], [0.0, 0.0],\n",
    "                                   [0.0, 0.0], [0.0, 0.0], [-0.3, 0.0]], dtype=tf.float32) \n",
    "moving_vectors = moving_vectors[tf.newaxis,::]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 9, 2)\n",
      "(1, 625, 25, 25, 2)\n",
      "(1, 25, 25, 25, 25)\n"
     ]
    }
   ],
   "source": [
    "print(moving_vectors.shape)\n",
    "inlier_mask = generate_inlier_mask(moving_vectors, (25,25))\n",
    "print(inlier_mask.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7fe2282d4f98>"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(inlier_mask[0,24,24])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(identity_mask.shape)\n",
    "print(remaps.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_identity_mask = tf.reshape(identity_mask, [batch_size*height*width, height, width, 1])\n",
    "_remaps = tf.tile(remaps, [height*width, 1, 1, 1])\n",
    "print(_identity_mask.shape)\n",
    "print(_remaps.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow_addons as tfa\n",
    "sampled_image = tfa.image.resampler(_identity_mask, _remaps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sampled_image.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sampled_image = tf.reshape(sampled_image, [batch_size, height, width, height, width])\n",
    "print(sampled_image.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(identity_mask[0,:,:,0,0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(sampled_image[0,:,:,0,0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(identity_mask[0,:,:,1,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(sampled_image[0,:,:,1,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(identity_mask[0,:,:,2,2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(sampled_image[0,:,:,2,2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sampled_image = tfa.image.resampler(tf.ones([1,8,8,3]), remaps[:1,::])\n",
    "plt.imshow(sampled_image.numpy()[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.zeros([3,8,8,3], np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x[0,0,0] = 1\n",
    "x[1,1,1] = 1\n",
    "x[2,2,2] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(x[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(x[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(x[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sampled_image = tfa.image.resampler(x, remaps[:3,::])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(sampled_image.numpy()[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(sampled_image.numpy()[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(sampled_image.numpy()[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "identity_mask = tf.reshape(identity_mask, [-1, height,width])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "remaps.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "identity_mask[0][:,:,0,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "identity_mask.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#calculate estimated coordinates of source grids on target feature grids\n",
    "control_points = tf.constant([[-1.0, -1.0], [0.0, -1.0], [1.0, -1.0],\n",
    "                                   [-1.0, 0.0], [0.0, 0.0], [1.0, 0.0],\n",
    "                                   [-1.0, 1.0], [0.0, 1.0], [1.0, 1.0]], dtype=tf.float32)  \n",
    "\n",
    "\n",
    "moving_vectors = tf.constant([[0.1, 0.0], [0.1, 0.0], [0.1, 0.0],\n",
    "                                   [0.1, 0.0], [0.1, 0.0], [0.1, 0.0],\n",
    "                                   [0.1, 0.0], [0.1, 0.0], [0.1, 0.0]], dtype=tf.float32) \n",
    "\n",
    "control_points = control_points[tf.newaxis,::]\n",
    "moving_vectors = moving_vectors[tf.newaxis,::]\n",
    "\n",
    "x_s, y_s = tps(control_points, -moving_vectors, (200,200))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_s.shape, y_s.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_name = \"sample_dataset/060_0000.png\"\n",
    "img = cv2.imread(img_name)[:,:,::-1]\n",
    "img = cv2.resize(img, (200, 200) ,interpolation=cv2.INTER_AREA)\n",
    "plt.imshow(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = img[np.newaxis,::]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow_addons as tfa\n",
    "s_img = img/255\n",
    "s_img = s_img.astype(np.float32)\n",
    "sampled_image = tfa.image.resampler(s_img, tf.stack([x_s, y_s], axis=-1))\n",
    "plt.imshow(sampled_image[0].numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_inlier_mask(moving_vectors, map_size, thresh=30):\n",
    "    batch_size = len(geo_parameters)\n",
    "    height, width = map_size\n",
    "    \n",
    "    #generate identity masks of batch_size\n",
    "    identity_mask = np.zeros((height*width*height*width))\n",
    "    idx_list = list(range(0, height*width*height*width, height*width+1))\n",
    "    identity_mask[idx_list] = 1\n",
    "    identity_mask = np.reshape(identity_mask, (1, height,width,height,width))\n",
    "    \n",
    "    identity_mask = tf.constant(identity_mask, tf.float32)\n",
    "    identity_mask = tf.tile(identity_mask, [batch_size,1,1,1,1]) #[BN,H,W,H,W]\n",
    "    \n",
    "    #calculate estimated coordinates of source grids on target feature grids\n",
    "    control_points = tf.constant([[-1.0, -1.0], [0.0, -1.0], [1.0, -1.0],\n",
    "                                   [-1.0, 0.0], [0.0, 0.0], [1.0, 0.0],\n",
    "                                   [-1.0, 1.0], [0.0, 1.0], [1.0, 1.0]], dtype=tf.float32)  \n",
    "    control_points = tf.tile(control_points[tf.newaxis,::], [batch_size, 1, 1]) # [BN, 9, 2]\n",
    "    x_s, y_s = tps(control_points, -moving_vectors, out_size)\n",
    "    remaps = tf.stack([x_s, y_s], axis=-1)\n",
    "    \n",
    "    \n",
    "    x_t = tf.tile(tf.reshape(tf.linspace(0.0, width-1.0, width), [1, width]), [height, 1])\n",
    "    y_t = tf.tile(tf.reshape(tf.linspace(0.0, height-1.0, height), [height, 1]), [1, width])    \n",
    "    x_t = tf.tile(x_t[tf.newaxis,::], [batch_size, 1, 1]) # [BN, H, W]\n",
    "    y_t = tf.tile(y_t[tf.newaxis,::], [batch_size, 1, 1]) # [BN, H, W]\n",
    "    \n",
    "    control_points = tf.constant([[-1.0, -1.0], [0.0, -1.0], [1.0, -1.0],\n",
    "                                   [-1.0, 0.0], [0.0, 0.0], [1.0, 0.0],\n",
    "                                   [-1.0, 1.0], [0.0, 1.0], [1.0, 1.0]], dtype=tf.float32)    \n",
    "    control_points = tf.tile(control_points[tf.newaxis,::], [batch_size, 1, 1]) # [BN, 9, 2]\n",
    "    x_p, y_p = tps(control_points, -moving_vectors, (height, width))\n",
    "    \n",
    "    x_t, y_t = x_t[:,:,:,tf.newaxis,tf.newaxis], y_t[:,:,:,tf.newaxis,tf.newaxis] #[BN,H,W,1,1]\n",
    "    x_p, y_p = x_p[:,tf.newaxis,tf.newaxis,:,:], y_p[:,tf.newaxis,tf.newaxis,:,:] #[BN,1,1,H,W]\n",
    "    # L2 distance of grids of featureA and grids of featureB, transformed by the estimated geometric transformation.\n",
    "    l2_dist = tf.sqrt(tf.pow(x_t - x_p, 2) + tf.pow(y_t - y_p, 2)) \n",
    "    #inlier_mask = l2_dist\n",
    "    inlier_mask = tf.cond(l2_dist < height/thresh, 1, 0)\n",
    "    return inlier_mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mask_id = tf.zeros([4,4,4*4])\n",
    "idx_list = list(range(0, tf.size(mask_id), mask_id.shape[2]+1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.reshape(mask_id.reshape((-1))[idx_list]=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type(mask_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mask_id.size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mask_id.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mask_id = np.zeros((w_matches,h_matches,w_matches*h_matches))\n",
    "idx_list = list(range(0, mask_id.size, mask_id.shape[2]+1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mask_id = np.reshape(mask_id, [4,4,4,4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mask_id[0,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "generate_inlier_mask(geo_parameters, (25, 25))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cnngeo(A, B)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CNN_geotransform(tf.keras.Model):\n",
    "    def __init__(self, feature_extractor, num_param):\n",
    "        super(CNN_geotransform, self).__init__()\n",
    "        self.feature_extractor = feature_extractor\n",
    "        self.correlation_net = Correlation_network()\n",
    "        self.regressor = Spatial_regressor(9*2)\n",
    "    def call(self, imageA, imageB):\n",
    "        featureA = self.feature_extractor(imageA)\n",
    "        featureB = self.feature_extractor(imageB)\n",
    "        featureA = feature_l2_normalization(featureA)\n",
    "        featureB = feature_l2_normalization(featureB)\n",
    "        correlations = self.correlation_net(featureA, featureB)\n",
    "        correlations = tf.keras.layers.Activation(\"relu\")(correlations)\n",
    "        correlations = normalize_correlation(correlations)\n",
    "        geo_parameters = self.regressor(correlations)\n",
    "        return geo_parameters, correlations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Correlation_network(tf.keras.layers.Layer):\n",
    "    def __init__(self):\n",
    "        super(Correlation_network, self).__init__()\n",
    "\n",
    "    def call(self, feature_A, feature_B):\n",
    "        # featureA : feature information from source image\n",
    "        # featureB : feature information from target image\n",
    "        #assert feature_A.shape == feature_B.shape\n",
    "        # new feature A and feature B have new shape of tensors.\n",
    "        # featureA has tensor shape as [batch, HA, WA, 1, 1, depth]\n",
    "        # featureB has tensor shape as [batch, 1, 1, HB, WB, depth]\n",
    "        feature_A = feature_A[:, :, :, tf.newaxis, tf.newaxis, :]\n",
    "        feature_B = feature_B[:, tf.newaxis, tf.newaxis, :, :, :]\n",
    "        # correlation score has tensor shape as [batch, HA, WA, HB, WB]\n",
    "        corr_score = tf.reduce_sum(tf.multiply(feature_A, feature_B), axis=-1)\n",
    "        return corr_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from models.module import feature_l2_normalization, normalize_correlation\n",
    "\n",
    "class CNN_align(tf.keras.Model):\n",
    "    def __init__(self, feature_extractor, regressor, thresh=30):\n",
    "        super(CNN_align, self).__init__()\n",
    "        self.model_name = 'CNNalign'\n",
    "        self.feature_extractor = feature_extractor\n",
    "        self.correlation_net = Correlation_network()\n",
    "        self.regressor = regressor\n",
    "        self.thresh = thresh\n",
    "    def call(self, imageA, imageB):\n",
    "        featureA = self.feature_extractor(imageA)\n",
    "        featureB = self.feature_extractor(imageB)\n",
    "        featureA = feature_l2_normalization(featureA)\n",
    "        featureB = feature_l2_normalization(featureB)\n",
    "        correlations = self.correlation_net(featureA, featureB)\n",
    "        correlations = tf.keras.layers.Activation(\"relu\")(correlations)\n",
    "        correlations = normalize_correlation(correlations)\n",
    "        geo_parameters = self.regressor(correlations)        \n",
    "        \n",
    "        map_size = correlations.shape[-2:]\n",
    "        inlier_masks = generate_inlier_mask(geo_parameters, map_size, thresh = self.thresh)\n",
    "        inlier_matching = correlations * inlier_masks  # B, H, W, H, W\n",
    "        inlier_count = tf.reduce_sum(inlier_matching, axis=(1, 2, 3, 4))\n",
    "        return inlier_matching, inlier_count\n",
    "\n",
    "    def save(self, ckpt_path):\n",
    "        self.cnn_geo.save(ckpt_path)\n",
    "\n",
    "    def load(self, ckpt_path):\n",
    "        self.cnn_geo.load(ckpt_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_extractor = cnngeo.feature_extractor\n",
    "feature_extractor.layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "regressor = cnngeo.regressor\n",
    "regressor.layers[0].layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cnnalign = CNN_align(feature_extractor, regressor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cnnalign(A,B)\n",
    "cnnalign.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.keras.utils.plot_model(cnnalign)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cnnalign.cnn_geo.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cnnalign.cnn_geo.regressor.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp = cnnalign.cnn_geo.regressor.get_weights()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp[0].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3.Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loss_fn(pred):\n",
    "    return tf.reduce_mean(-pred)\n",
    "\n",
    "@tf.function\n",
    "def train_step(image_A, image_B, label, model, optimizer):\n",
    "    with tf.GradientTape() as tape:\n",
    "        inlier_matching, inlier_count = model(image_A, image_B)\n",
    "        loss = loss_fn(inlier_count)\n",
    "    gradients = tape.gradient(loss, model.trainable_variables)\n",
    "    optimizer.apply_gradients(zip(gradients, model.trainable_variables))\n",
    "    return loss, gradients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = tf.keras.optimizers.Adam(learning_rate=1E-4)\n",
    "\n",
    "train_loss = tf.metrics.Mean(name='train_loss')\n",
    "x_axis = []\n",
    "y_loss = []\n",
    "for epoch in range(1):\n",
    "    for step, (image_a, image_b, labels) in enumerate(ds):\n",
    "        t_loss, _gradients = train_step(image_a, image_b, labels, cnnalign, optimizer)\n",
    "        train_loss(t_loss)\n",
    "    template = 'Epoch {}, Loss: {}'\n",
    "    print(template.format(epoch + 1, train_loss.result()))\n",
    "    x_axis.append(epoch)\n",
    "    y_loss.append(train_loss.result().numpy())\n",
    "    train_loss.reset_states()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_gradients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure()\n",
    "axis = fig.add_subplot(111)\n",
    "axis.title.set_text(\"training_loss\")\n",
    "axis.set_xlabel(\"epoch\")\n",
    "axis.set_ylabel(\"training loss\")\n",
    "axis.plot(np.array(x_axis), np.array(y_loss))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cnnalign.trainable_variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_tmp = cnnalign.cnn_geo.regressor.get_weights()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for A, B, p in ds.take(1):\n",
    "    print(A.shape, B.shape)\n",
    "    preds = cnngeo(A, B)\n",
    "\n",
    "warping_images = []\n",
    "output_size = A.shape[1:3]\n",
    "control_points = tf.constant([[-1.0, -1.0], [0.0, -1.0], [1.0, -1.0],\n",
    "                               [-1.0, 0.0], [0.0, 0.0], [1.0, 0.0],\n",
    "                               [-1.0, 1.0], [0.0, 1.0], [1.0, 1.0]], dtype=tf.float32)\n",
    "for image, pred in zip(A, preds):\n",
    "    x_s, y_s = tps(control_points[tf.newaxis,::], -pred[tf.newaxis,::], output_size)\n",
    "    image = image.numpy()\n",
    "    warping_images.append(cv2.remap(image, x_s[0].numpy(), y_s[0].numpy(), cv2.INTER_CUBIC))\n",
    "\n",
    "warping_images = np.array(warping_images)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def restore_original_image_from_array(x, data_format=None):\n",
    "    mean = [103.939, 116.779, 123.68]\n",
    "\n",
    "    # Zero-center by mean pixel\n",
    "    if data_format == 'channels_first':\n",
    "        if x.ndim == 3:\n",
    "            x[0, :, :] += mean[0]\n",
    "            x[1, :, :] += mean[1]\n",
    "            x[2, :, :] += mean[2]\n",
    "        else:\n",
    "            x[:, 0, :, :] += mean[0]\n",
    "            x[:, 1, :, :] += mean[1]\n",
    "            x[:, 2, :, :] += mean[2]\n",
    "    else:\n",
    "        x[..., 0] += mean[0]\n",
    "        x[..., 1] += mean[1]\n",
    "        x[..., 2] += mean[2]\n",
    "\n",
    "    if data_format == 'channels_first':\n",
    "        # 'BGR'->'RGB'\n",
    "        if x.ndim == 3:\n",
    "            x = x[::-1, ...]\n",
    "        else:\n",
    "            x = x[:, ::-1, ...]\n",
    "    else:\n",
    "        # 'BGR'->'RGB'\n",
    "        x = x[..., ::-1]\n",
    "\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(A[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(B[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(warping_images[4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(restore_original_image_from_array(B[1].numpy())/255)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(restore_original_image_from_array(warping_images[1])/255)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(images[1]/255)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Comparison between ground-truth and prediction of motion vectors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(p.shape)\n",
    "print(preds.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for A, B, p in ds.take(1):\n",
    "    print(A.shape, B.shape)\n",
    "    preds = cnngeo(A, B)\n",
    "\n",
    "warping_images = []\n",
    "output_size = A.shape[1:3]\n",
    "control_points = tf.constant([[-1.0, -1.0], [0.0, -1.0], [1.0, -1.0],\n",
    "                               [-1.0, 0.0], [0.0, 0.0], [1.0, 0.0],\n",
    "                               [-1.0, 1.0], [0.0, 1.0], [1.0, 1.0]], dtype=tf.float32)\n",
    "for image, pred in zip(A, preds):\n",
    "    x_s, y_s = tps(control_points[tf.newaxis,::], -pred[tf.newaxis,::], output_size)\n",
    "    image = image.numpy()\n",
    "    warping_images.append(cv2.remap(image, x_s[0].numpy(), y_s[0].numpy(), cv2.INTER_CUBIC))\n",
    "\n",
    "warping_images = np.array(warping_images)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dev_utils import draw\n",
    "def decode(x):\n",
    "    x = (x + 1)/2\n",
    "    if type(x) != np.ndarray:\n",
    "        return x.numpy()\n",
    "    else:\n",
    "        return x\n",
    "def makeBorder(image, bordersize):\n",
    "    draw_image = image.copy()\n",
    "    color = [1, 1, 1]\n",
    "    draw_image = cv2.copyMakeBorder(draw_image,\n",
    "                                    top=bordersize, bottom=bordersize,\n",
    "                                    left=bordersize, right=bordersize,\n",
    "                                    borderType=cv2.BORDER_CONSTANT,\n",
    "                                    value=color)\n",
    "    return draw_image\n",
    "\n",
    "\n",
    "def draw_point(image, bordersize, points=None):\n",
    "    draw_image = image.copy()\n",
    "    H, W, C = draw_image.shape\n",
    "    if points is None:\n",
    "        points = np.array([[0.0, 0.0], [0.5, 0.0], [1.0, 0.0],\n",
    "                           [0.0, 0.5], [0.5, 0.5], [1.0, 0.5],\n",
    "                           [0.0, 1.0], [0.5, 1.0], [1.0, 1.0]])\n",
    "    points = points * (W - 2 * bordersize, H - 2 * bordersize)\n",
    "    points = points.astype(np.int32)\n",
    "    for pnt in points:\n",
    "        draw_image = cv2.circle(draw_image, tuple(\n",
    "            pnt + bordersize), 1, (0, 1, 0), -1)\n",
    "    return draw_image\n",
    "\n",
    "\n",
    "def draw_arrow(image, bordersize, motion_parameters, src_points=None):\n",
    "    draw_image = image.copy()\n",
    "    H, W, C = image.shape\n",
    "    if src_points is None:\n",
    "        src_points = np.array([[0.0, 0.0], [0.5, 0.0], [1.0, 0.0],\n",
    "                               [0.0, 0.5], [0.5, 0.5], [1.0, 0.5],\n",
    "                               [0.0, 1.0], [0.5, 1.0], [1.0, 1.0]])\n",
    "    src_points = src_points * (W - 2 * bordersize, H - 2 * bordersize)\n",
    "    src_points = src_points.astype(np.int32)\n",
    "    motion_parameters = motion_parameters * \\\n",
    "        (W - 2 * bordersize, H - 2 * bordersize)\n",
    "    dst_points = src_points + motion_parameters\n",
    "    dst_points = dst_points.astype(np.int32)\n",
    "\n",
    "    for src, dst in zip(src_points, dst_points):\n",
    "        draw_image = cv2.arrowedLine(draw_image, tuple(src + bordersize), tuple(dst + bordersize),\n",
    "                                     (1, 0, 0), 1)\n",
    "    return draw_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "motion_vector = p[0].numpy()\n",
    "\n",
    "padd = 50\n",
    "white_board = makeBorder(A[0].numpy(), padd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(draw_point(white_board, padd))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(draw_arrow(white_board, padd, p[0].numpy()/2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(B[0].numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(draw_arrow(white_board, padd, preds[0].numpy()/2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(warping_images[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
